"""
å¢å¼ºå½¢æ€æ£€æµ‹å™¨æ¨¡å—
é›†æˆä¸“å®¶çº§MACDèƒŒç¦» + å½¢æ€è¯†åˆ«ç®—æ³•
åŸºäºå¤§ä½¬æä¾›çš„ä¸“ä¸šä»£ç ï¼Œé€‚é…ç°æœ‰ç³»ç»Ÿæ¶æ„
"""

import numpy as np
from scipy.signal import find_peaks
import talib as ta
from typing import List, Tuple, Optional, Dict, Any
from dataclasses import dataclass, field
from datetime import datetime
import logging
from enum import Enum
import pandas as pd

from config.config_manager import ConfigManager
from utils.logger import get_logger, performance_monitor
# ğŸ†• ä»»åŠ¡4.2: å¯¼å…¥æ”¹è¿›ç‰ˆåŒé‡å½¢æ€æ£€æµ‹å™¨
from core.improved_double_pattern_detector import ImprovedDoublePatternDetector, PatternSignal as DoublePatternSignal

class PatternType(Enum):
    """å½¢æ€ç±»å‹æšä¸¾"""
    ENGULFING_BULL = "engulfing_bull"
    ENGULFING_BEAR = "engulfing_bear"
    HEAD_SHOULDER_BEAR = "head_shoulder_bear"
    HEAD_SHOULDER_BULL = "head_shoulder_bull"
    CONVERGENCE_TRIANGLE_BULL = "convergence_triangle_bull"
    CONVERGENCE_TRIANGLE_BEAR = "convergence_triangle_bear"
    # ğŸ†• ä»»åŠ¡4.2: æ·»åŠ Wåº•/åŒé¡¶å½¢æ€ç±»å‹
    DOUBLE_BOTTOM_BULL = "double_bottom_bull"  # Wåº•çœ‹æ¶¨
    DOUBLE_TOP_BEAR = "double_top_bear"        # åŒé¡¶çœ‹è·Œ

class DivergenceType(Enum):
    """èƒŒç¦»ç±»å‹æšä¸¾"""
    BEARISH = "bearish"
    BULLISH = "bullish"

@dataclass
class DivergenceSignal:
    """èƒŒç¦»ä¿¡å·æ•°æ®ç»“æ„"""
    type: DivergenceType
    strength: float
    confidence: float
    indices: List[int]
    timestamp: datetime = field(default_factory=datetime.now)
    macd_values: List[float] = field(default_factory=list)
    price_values: List[float] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'type': self.type.value,
            'strength': self.strength,
            'confidence': self.confidence,
            'indices': self.indices,
            'timestamp': self.timestamp.isoformat(),
            'macd_values': self.macd_values,
            'price_values': self.price_values
        }

@dataclass
class PatternSignal:
    """å½¢æ€ä¿¡å·æ•°æ®ç»“æ„"""
    type: PatternType
    confidence: float
    details: Dict[str, Any]
    timestamp: datetime = field(default_factory=datetime.now)
    validity_period: int = 24  # æœ‰æ•ˆæœŸï¼ˆå°æ—¶ï¼‰
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'type': self.type.value,
            'confidence': self.confidence,
            'details': self.details,
            'timestamp': self.timestamp.isoformat(),
            'validity_period': self.validity_period
        }

class EnhancedPatternDetector:
    """
    å¢å¼ºå½¢æ€æ£€æµ‹å™¨ - åŸºäºä¸“å®¶ä»£ç ä¼˜åŒ–
    é›†æˆMACDèƒŒç¦»æ£€æµ‹å’Œå½¢æ€è¯†åˆ«åŠŸèƒ½
    """
    
    def __init__(self, config_manager: ConfigManager):
        self.config = config_manager
        self.logger = get_logger(__name__)
        
        # è·å–é…ç½®
        self.trading_config = self.config.get_trading_config()
        self.macd_config = self.trading_config.macd
        self.divergence_config = self.trading_config.macd_divergence
        self.pattern_config = self.config.get_signal_config()
        
        # MACDå‚æ•°
        self.macd_fast = self.macd_config.fast
        self.macd_slow = self.macd_config.slow
        self.macd_signal = self.macd_config.signal
        
        # æ£€æµ‹å‚æ•°
        self.lookback = self.divergence_config.lookback_period
        self.min_distance = self.divergence_config.min_peak_distance
        self.prominence_mult = self.divergence_config.prominence_mult
        self.min_gap = 0.1
        self.min_consecutive = self.divergence_config.consecutive_signals
        self.tolerance = 2
        self.vol_factor_mult = self.pattern_config.vol_factor_mult
        
        # æ”¯æŒçš„å½¢æ€
        pattern_list = self.config.get_param('market_conditions.pattern_recognition.patterns', 
                                           ["ENGULFING", "HEAD_SHOULDER", "CONVERGENCE_TRIANGLE", "DOUBLE_PATTERNS"])
        self.morph_patterns = pattern_list
        
        # ğŸ†• ä»»åŠ¡4.2: åˆå§‹åŒ–æ”¹è¿›ç‰ˆåŒé‡å½¢æ€æ£€æµ‹å™¨
        self.double_pattern_detector = ImprovedDoublePatternDetector()
        
        # æ£€æµ‹ç»Ÿè®¡
        self.detection_stats = {
            'total_detections': 0,
            'divergence_count': 0,
            'pattern_count': 0,
            'double_pattern_count': 0,  # ğŸ†• æ·»åŠ åŒé‡å½¢æ€ç»Ÿè®¡
            'high_confidence_signals': 0,
            'false_positive_rate': 0.0
        }
        
        # ä¿¡å·å†å²
        self.signal_history: List[Dict] = []
        self.max_history = 100
        
        self.logger.info("å¢å¼ºå½¢æ€æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
    
    @performance_monitor
    def compute_macd(self, closes: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        è®¡ç®—MACDæŒ‡æ ‡ (ä½¿ç”¨ta-lib)
        
        Args:
            closes: æ”¶ç›˜ä»·æ•°ç»„
            
        Returns:
            (macd_line, signal_line, histogram)
        """
        try:
            if len(closes) < self.macd_slow + self.macd_signal:
                raise ValueError(f"æ•°æ®é•¿åº¦ä¸è¶³ï¼Œéœ€è¦è‡³å°‘{self.macd_slow + self.macd_signal}ä¸ªæ•°æ®ç‚¹")
            
            macd, signal, hist = ta.MACD(
                closes, 
                fastperiod=self.macd_fast, 
                slowperiod=self.macd_slow, 
                signalperiod=self.macd_signal
            )
            
            return macd, signal, hist
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—MACDå¤±è´¥: {e}")
            raise
    
    @performance_monitor
    def detect_divergence(self, highs: np.ndarray, lows: np.ndarray, 
                         closes: np.ndarray, vol_factor: float = 0.0) -> List[DivergenceSignal]:
        """
        æ£€æµ‹MACDèƒŒç¦» - åŸºäºä¸“å®¶ç®—æ³•ä¼˜åŒ–
        
        Args:
            highs: æœ€é«˜ä»·æ•°ç»„
            lows: æœ€ä½ä»·æ•°ç»„  
            closes: æ”¶ç›˜ä»·æ•°ç»„
            vol_factor: æ³¢åŠ¨æ€§å› å­ï¼Œç”¨äºåŠ¨æ€è°ƒæ•´é˜ˆå€¼
            
        Returns:
            èƒŒç¦»ä¿¡å·åˆ—è¡¨
        """
        try:
            if len(closes) < self.lookback:
                self.logger.warning(f"æ•°æ®é•¿åº¦ä¸è¶³: {len(closes)} < {self.lookback}")
                return []
            
            # è®¡ç®—MACD
            macd, signal, hist = self.compute_macd(closes[-self.lookback:])
            
            # è¿‡æ»¤NaNå€¼
            valid_mask = ~(np.isnan(macd) | np.isnan(signal) | np.isnan(hist))
            if not np.any(valid_mask):
                self.logger.warning("MACDè®¡ç®—ç»“æœå…¨ä¸ºNaN")
                return []
            
            macd = macd[valid_mask]
            signal = signal[valid_mask]
            hist = hist[valid_mask]
            
            # è°ƒæ•´å¯¹åº”çš„ä»·æ ¼æ•°æ®
            price_start_idx = len(closes) - len(macd)
            adjusted_highs = highs[price_start_idx:]
            adjusted_lows = lows[price_start_idx:]
            
            # åŠ¨æ€é˜ˆå€¼
            gap_thresh = self.min_gap + vol_factor * self.vol_factor_mult
            
            # è®¡ç®—prominenceé˜ˆå€¼
            price_prominence = self.prominence_mult * np.std(adjusted_highs)
            macd_prominence = self.prominence_mult * np.std(hist)
            
            # æ£€æµ‹ä»·æ ¼å³°è°·
            price_peaks, _ = find_peaks(
                adjusted_highs, 
                distance=self.min_distance, 
                prominence=max(price_prominence, 0.001)  # é˜²æ­¢prominenceä¸º0
            )
            price_valleys, _ = find_peaks(
                -adjusted_lows, 
                distance=self.min_distance, 
                prominence=max(price_prominence, 0.001)
            )
            
            # æ£€æµ‹MACDæŸ±çŠ¶å›¾å³°è°·
            macd_peaks, _ = find_peaks(
                hist, 
                distance=self.min_distance, 
                prominence=max(macd_prominence, 0.001)
            )
            macd_valleys, _ = find_peaks(
                -hist, 
                distance=self.min_distance, 
                prominence=max(macd_prominence, 0.001)
            )
            
            signals = []
            
            # æ£€æµ‹çœ‹è·ŒèƒŒç¦»
            bear_signals = self._find_consecutive_divergence(
                price_peaks, macd_peaks, adjusted_highs, hist, 
                is_bearish=True, gap_thresh=gap_thresh
            )
            signals.extend(bear_signals)
            
            # æ£€æµ‹çœ‹æ¶¨èƒŒç¦»
            bull_signals = self._find_consecutive_divergence(
                price_valleys, macd_valleys, -adjusted_lows, -hist, 
                is_bearish=False, gap_thresh=gap_thresh
            )
            signals.extend(bull_signals)
            
            # æ›´æ–°ç»Ÿè®¡
            self.detection_stats['total_detections'] += 1
            self.detection_stats['divergence_count'] += len(signals)
            
            # è®°å½•é«˜ç½®ä¿¡åº¦ä¿¡å·
            high_conf_signals = [s for s in signals if s.confidence > 0.7]
            self.detection_stats['high_confidence_signals'] += len(high_conf_signals)
            
            return signals
            
        except Exception as e:
            self.logger.error(f"èƒŒç¦»æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def _find_consecutive_divergence(self, price_extrema: np.ndarray, macd_extrema: np.ndarray,
                                   prices: np.ndarray, macd: np.ndarray, 
                                   is_bearish: bool, gap_thresh: float) -> List[DivergenceSignal]:
        """
        æŸ¥æ‰¾è¿ç»­èƒŒç¦» - æ ¸å¿ƒç®—æ³•
        
        Args:
            price_extrema: ä»·æ ¼æå€¼ç´¢å¼•
            macd_extrema: MACDæå€¼ç´¢å¼•
            prices: ä»·æ ¼æ•°ç»„
            macd: MACDæ•°ç»„
            is_bearish: æ˜¯å¦ä¸ºçœ‹è·ŒèƒŒç¦»
            gap_thresh: é—´éš”é˜ˆå€¼
            
        Returns:
            èƒŒç¦»ä¿¡å·åˆ—è¡¨
        """
        signals = []
        
        if len(price_extrema) < self.min_consecutive or len(macd_extrema) < self.min_consecutive:
            return signals
        
        price_extrema = np.sort(price_extrema)
        macd_extrema = np.sort(macd_extrema)
        
        for start in range(len(price_extrema) - self.min_consecutive + 1):
            seq_price = price_extrema[start:start + self.min_consecutive]
            seq_macd = []
            
            # å¯»æ‰¾å¯¹åº”çš„MACDæå€¼
            for idx in seq_price:
                closest_macd = self._find_closest(macd_extrema, idx)
                if closest_macd is None:
                    break
                seq_macd.append(closest_macd)
            
            if len(seq_macd) != self.min_consecutive:
                continue
            
            # æ£€æŸ¥æŸ±è½¬è™šæ¡ä»¶ - ä¸“å®¶å»ºè®®çš„å…³é”®è¿‡æ»¤
            turn_virtual = self._check_turn_virtual(macd, seq_macd, is_bearish)
            if not turn_virtual:
                continue
            
            # è®¡ç®—èƒŒç¦»å¼ºåº¦
            div_count = 0
            total_strength = 0
            price_values = []
            macd_values = []
            
            for i in range(1, self.min_consecutive):
                price_diff = prices[seq_price[i]] - prices[seq_price[i-1]]
                macd_diff = macd[seq_macd[i]] - macd[seq_macd[i-1]]
                
                price_values.append(prices[seq_price[i]])
                macd_values.append(macd[seq_macd[i]])
                
                # èƒŒç¦»æ¡ä»¶æ£€æŸ¥
                is_divergence = False
                if is_bearish:
                    # çœ‹è·ŒèƒŒç¦»ï¼šä»·æ ¼æ–°é«˜ï¼ŒMACDæ–°ä½
                    is_divergence = price_diff > 0 and macd_diff < 0
                else:
                    # çœ‹æ¶¨èƒŒç¦»ï¼šä»·æ ¼æ–°ä½ï¼ŒMACDæ–°é«˜
                    is_divergence = price_diff < 0 and macd_diff > 0
                
                if is_divergence:
                    # è®¡ç®—èƒŒç¦»å¼ºåº¦
                    strength = abs(macd_diff / price_diff) if abs(price_diff) > 1e-8 else 0
                    if strength > gap_thresh:
                        div_count += 1
                        total_strength += strength
            
            # ç”Ÿæˆä¿¡å·
            if div_count >= self.min_consecutive - 1:
                avg_strength = total_strength / div_count if div_count > 0 else 0
                confidence = self._calculate_divergence_confidence(
                    avg_strength, gap_thresh, div_count
                )
                
                signal_type = DivergenceType.BEARISH if is_bearish else DivergenceType.BULLISH
                
                signal = DivergenceSignal(
                    type=signal_type,
                    strength=avg_strength,
                    confidence=confidence,
                    indices=seq_price.tolist(),
                    macd_values=macd_values,
                    price_values=price_values
                )
                
                signals.append(signal)
        
        return signals
    
    def _check_turn_virtual(self, macd: np.ndarray, seq_macd: List[int], is_bearish: bool) -> bool:
        """
        æ£€æŸ¥æŸ±è½¬è™šæ¡ä»¶ - ä¸“å®¶å»ºè®®çš„å…³é”®è¿‡æ»¤
        
        Args:
            macd: MACDæŸ±çŠ¶å›¾æ•°ç»„
            seq_macd: MACDæå€¼åºåˆ—
            is_bearish: æ˜¯å¦ä¸ºçœ‹è·ŒèƒŒç¦»
            
        Returns:
            æ˜¯å¦æ»¡è¶³æŸ±è½¬è™šæ¡ä»¶
        """
        try:
            if not seq_macd:
                return False
            
            latest_macd = macd[seq_macd[-1]]
            
            if is_bearish:
                # çœ‹è·ŒèƒŒç¦»ï¼šMACDæŸ±åº”è¯¥ä»æ­£è½¬è´Ÿï¼ˆè½¬è™šï¼‰
                return latest_macd < 0
            else:
                # çœ‹æ¶¨èƒŒç¦»ï¼šMACDæŸ±åº”è¯¥ä»è´Ÿè½¬æ­£ï¼ˆè½¬è™šï¼‰
                return latest_macd > 0
                
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥æŸ±è½¬è™šå¤±è´¥: {e}")
            return False
    
    def _calculate_divergence_confidence(self, avg_strength: float, gap_thresh: float, div_count: int) -> float:
        """
        è®¡ç®—èƒŒç¦»ç½®ä¿¡åº¦
        
        Args:
            avg_strength: å¹³å‡å¼ºåº¦
            gap_thresh: é—´éš”é˜ˆå€¼
            div_count: èƒŒç¦»è®¡æ•°
            
        Returns:
            ç½®ä¿¡åº¦ (0-1)
        """
        try:
            # åŸºç¡€ç½®ä¿¡åº¦
            base_confidence = min((avg_strength / gap_thresh) * 0.5 + 0.5, 1.0)
            
            # è¿ç»­æ€§åŠ æˆ
            consecutive_bonus = min((div_count - 1) * 0.1, 0.3)
            
            # æœ€ç»ˆç½®ä¿¡åº¦
            final_confidence = min(base_confidence + consecutive_bonus, 1.0)
            
            return final_confidence
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—èƒŒç¦»ç½®ä¿¡åº¦å¤±è´¥: {e}")
            return 0.5
    
    def _find_closest(self, extrema: np.ndarray, target_idx: int) -> Optional[int]:
        """
        å¯»æ‰¾æœ€æ¥è¿‘çš„æå€¼ç´¢å¼•
        
        Args:
            extrema: æå€¼ç´¢å¼•æ•°ç»„
            target_idx: ç›®æ ‡ç´¢å¼•
            
        Returns:
            æœ€æ¥è¿‘çš„æå€¼ç´¢å¼•æˆ–None
        """
        if len(extrema) == 0:
            return None
        
        distances = np.abs(extrema - target_idx)
        min_dist_idx = np.argmin(distances)
        
        if distances[min_dist_idx] <= self.tolerance:
            return extrema[min_dist_idx]
        
        return None
    
    @performance_monitor
    def detect_pattern(self, opens: np.ndarray, highs: np.ndarray, 
                      lows: np.ndarray, closes: np.ndarray) -> List[PatternSignal]:
        """
        æ£€æµ‹å½¢æ€ - åŸºäºä¸“å®¶ç®—æ³•ä¼˜åŒ–
        æ”¯æŒENGULFING/HEAD_SHOULDER/CONVERGENCE_TRIANGLE
        
        Args:
            opens: å¼€ç›˜ä»·æ•°ç»„
            highs: æœ€é«˜ä»·æ•°ç»„
            lows: æœ€ä½ä»·æ•°ç»„
            closes: æ”¶ç›˜ä»·æ•°ç»„
            
        Returns:
            å½¢æ€ä¿¡å·åˆ—è¡¨
        """
        try:
            signals = []
            
            if len(closes) < self.lookback:
                self.logger.warning(f"æ•°æ®é•¿åº¦ä¸è¶³è¿›è¡Œå½¢æ€æ£€æµ‹: {len(closes)} < {self.lookback}")
                return signals
            
            # ä½¿ç”¨lookbacké•¿åº¦çš„æ•°æ®
            opens_slice = opens[-self.lookback:]
            highs_slice = highs[-self.lookback:]
            lows_slice = lows[-self.lookback:]
            closes_slice = closes[-self.lookback:]
            
            # ğŸ”§ ä¸º_detect_double_patternsæä¾›è™šæ‹Ÿvolumesæ•°æ®
            # ç”±äºdetect_patternæ–¹æ³•ä¸æ¥å—volumeså‚æ•°ï¼Œæˆ‘ä»¬åˆ›å»ºè™šæ‹Ÿæ•°æ®
            volumes_slice = np.ones_like(closes_slice) * 1000000  # è™šæ‹Ÿæˆäº¤é‡æ•°æ®
            
            # 1. æ£€æµ‹åæ²¡å½¢æ€
            if "ENGULFING" in self.morph_patterns:
                engulfing_signals = self._detect_engulfing_pattern(
                    opens_slice, highs_slice, lows_slice, closes_slice
                )
                signals.extend(engulfing_signals)
            
            # 2. æ£€æµ‹å¤´è‚©å½¢æ€
            if "HEAD_SHOULDER" in self.morph_patterns:
                head_shoulder_signals = self._detect_head_shoulder_pattern(
                    highs_slice, lows_slice, closes_slice
                )
                signals.extend(head_shoulder_signals)
            
            # 3. æ£€æµ‹æ”¶æ•›ä¸‰è§’å½¢
            if "CONVERGENCE_TRIANGLE" in self.morph_patterns:
                triangle_signals = self._detect_convergence_triangle_pattern(
                    opens_slice, highs_slice, lows_slice, closes_slice
                )
                signals.extend(triangle_signals)
            
            # ğŸ†• ä»»åŠ¡4.2: æ£€æµ‹Wåº•/åŒé¡¶å½¢æ€
            if "DOUBLE_PATTERNS" in self.morph_patterns:
                double_pattern_signals = self._detect_double_patterns(
                    highs_slice, lows_slice, closes_slice, volumes_slice
                )
                signals.extend(double_pattern_signals)
            
            # æ›´æ–°ç»Ÿè®¡
            self.detection_stats['pattern_count'] += len(signals)
            
            return signals
            
        except Exception as e:
            self.logger.error(f"å½¢æ€æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def _detect_double_patterns(self, highs: np.ndarray, lows: np.ndarray, 
                               closes: np.ndarray, volumes: np.ndarray) -> List[PatternSignal]:
        """
        ğŸ†• ä»»åŠ¡4.2: æ£€æµ‹Wåº•/åŒé¡¶å½¢æ€
        
        Args:
            highs, lows, closes, volumes: OHLCVæ•°æ®
            
        Returns:
            æ£€æµ‹åˆ°çš„åŒé‡å½¢æ€ä¿¡å·åˆ—è¡¨
        """
        patterns = []
        
        try:
            # è°ƒç”¨æ”¹è¿›ç‰ˆåŒé‡å½¢æ€æ£€æµ‹å™¨
            double_patterns = self.double_pattern_detector.detect_patterns(
                highs, lows, closes, volumes
            )
            
            # è½¬æ¢ä¸ºæ ‡å‡†PatternSignalæ ¼å¼
            for dp in double_patterns:
                try:
                    # æ˜ å°„å½¢æ€ç±»å‹
                    if dp.type.value == "double_bottom_bull":
                        pattern_type = PatternType.DOUBLE_BOTTOM_BULL
                    elif dp.type.value == "double_top_bear":
                        pattern_type = PatternType.DOUBLE_TOP_BEAR
                    else:
                        continue
                    
                    # åˆ›å»ºæ ‡å‡†å½¢æ€ä¿¡å·
                    pattern_signal = PatternSignal(
                        type=pattern_type,
                        confidence=dp.confidence,
                        start_idx=dp.metadata.get('left_valley_idx', 0) if 'left_valley_idx' in dp.metadata else dp.metadata.get('left_peak_idx', 0),
                        end_idx=dp.metadata.get('right_valley_idx', len(closes)-1) if 'right_valley_idx' in dp.metadata else dp.metadata.get('right_peak_idx', len(closes)-1),
                        strength=min(dp.confidence * 100, 100),
                        direction='BULLISH' if pattern_type == PatternType.DOUBLE_BOTTOM_BULL else 'BEARISH',
                        entry_price=dp.entry_price,
                        stop_loss=dp.stop_loss,
                        take_profit=dp.target_price,
                        formation_bars=dp.formation_bars,
                        volume_confirmation=dp.volume_ratio > 1.0,
                        metadata={
                            'similarity_score': dp.similarity_score,
                            'rsi_confirmation': dp.rsi_confirmation,
                            'neckline': dp.metadata.get('neckline', dp.entry_price),
                            'confidence_breakdown': dp.metadata.get('confidence_breakdown', {}),
                            'double_pattern_detector': True  # æ ‡è¯†æ¥æº
                        }
                    )
                    
                    patterns.append(pattern_signal)
                    self.detection_stats['double_pattern_count'] += 1
                    
                    self.logger.info(f"âœ… æ£€æµ‹åˆ°{pattern_type.value}å½¢æ€: ç½®ä¿¡åº¦={dp.confidence:.2f}, "
                                   f"å‘¨æœŸ={dp.formation_bars}, ç›¸ä¼¼åº¦={dp.similarity_score:.2f}")
                    
                except Exception as e:
                    self.logger.error(f"è½¬æ¢åŒé‡å½¢æ€ä¿¡å·å¤±è´¥: {e}")
                    continue
            
            return patterns
            
        except Exception as e:
            self.logger.error(f"åŒé‡å½¢æ€æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def _detect_engulfing_pattern(self, opens: np.ndarray, highs: np.ndarray, 
                                lows: np.ndarray, closes: np.ndarray) -> List[PatternSignal]:
        """
        æ£€æµ‹åæ²¡å½¢æ€ - ä½¿ç”¨ta-lib
        
        Args:
            opens, highs, lows, closes: OHLCæ•°æ®
            
        Returns:
            åæ²¡å½¢æ€ä¿¡å·åˆ—è¡¨
        """
        signals = []
        
        try:
            engulfing = ta.CDLENGULFING(opens, highs, lows, closes)
            
            if engulfing[-1] != 0:
                if engulfing[-1] > 0:
                    # çœ‹æ¶¨åæ²¡
                    pattern_type = PatternType.ENGULFING_BULL
                    confidence = 0.8
                else:
                    # çœ‹è·Œåæ²¡
                    pattern_type = PatternType.ENGULFING_BEAR
                    confidence = 0.7
                
                # å¢å¼ºç½®ä¿¡åº¦è®¡ç®—
                confidence = self._enhance_engulfing_confidence(
                    opens, highs, lows, closes, confidence
                )
                
                signal = PatternSignal(
                    type=pattern_type,
                    confidence=confidence,
                    details={
                        'candle_index': len(closes) - 1,
                        'engulfing_value': int(engulfing[-1]),
                        'prev_candle_size': abs(closes[-2] - opens[-2]),
                        'curr_candle_size': abs(closes[-1] - opens[-1])
                    }
                )
                
                signals.append(signal)
                
        except Exception as e:
            self.logger.error(f"æ£€æµ‹åæ²¡å½¢æ€å¤±è´¥: {e}")
        
        return signals
    
    def _enhance_engulfing_confidence(self, opens: np.ndarray, highs: np.ndarray,
                                    lows: np.ndarray, closes: np.ndarray, 
                                    base_confidence: float) -> float:
        """
        å¢å¼ºåæ²¡å½¢æ€ç½®ä¿¡åº¦è®¡ç®—
        
        Args:
            opens, highs, lows, closes: OHLCæ•°æ®
            base_confidence: åŸºç¡€ç½®ä¿¡åº¦
            
        Returns:
            å¢å¼ºåçš„ç½®ä¿¡åº¦
        """
        try:
            # è®¡ç®—åæ²¡å¼ºåº¦
            prev_body = abs(closes[-2] - opens[-2])
            curr_body = abs(closes[-1] - opens[-1])
            engulfing_ratio = curr_body / prev_body if prev_body > 0 else 1
            
            # è®¡ç®—æˆäº¤é‡ç¡®è®¤ï¼ˆå¦‚æœæœ‰æˆäº¤é‡æ•°æ®ï¼‰
            volume_confirmation = 1.0  # ç®€åŒ–å¤„ç†
            
            # è®¡ç®—è¶‹åŠ¿èƒŒæ™¯
            trend_strength = self._calculate_trend_strength(closes)
            
            # ç»¼åˆè°ƒæ•´ç½®ä¿¡åº¦
            confidence_multiplier = min(1.2, 0.8 + engulfing_ratio * 0.1 + trend_strength * 0.1)
            enhanced_confidence = min(1.0, base_confidence * confidence_multiplier)
            
            return enhanced_confidence
            
        except Exception as e:
            self.logger.error(f"å¢å¼ºåæ²¡ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
            return base_confidence
    
    def _detect_head_shoulder_pattern(self, highs: np.ndarray, lows: np.ndarray, 
                                    closes: np.ndarray) -> List[PatternSignal]:
        """
        æ£€æµ‹å¤´è‚©å½¢æ€ - åŸºäºä¸“å®¶ç®—æ³•
        
        Args:
            highs: æœ€é«˜ä»·æ•°ç»„
            lows: æœ€ä½ä»·æ•°ç»„
            closes: æ”¶ç›˜ä»·æ•°ç»„
            
        Returns:
            å¤´è‚©å½¢æ€ä¿¡å·åˆ—è¡¨
        """
        signals = []
        
        try:
            # æ£€æµ‹å³°å€¼
            peaks_idx, _ = find_peaks(
                highs, 
                distance=self.min_distance, 
                prominence=self.prominence_mult * np.std(highs)
            )
            
            if len(peaks_idx) >= 3:
                # å–æœ€è¿‘çš„ä¸‰ä¸ªå³°å€¼
                left, head, right = peaks_idx[-3:]
                
                # éªŒè¯å¤´è‚©å½¢æ€
                if (highs[head] > highs[left] and 
                    highs[head] > highs[right]):
                    
                    # è®¡ç®—è‚©éƒ¨ç›¸ä¼¼åº¦
                    shoulder_diff = abs(highs[left] - highs[right])
                    shoulder_similarity = 1.0 - (shoulder_diff / highs[head])
                    
                    if shoulder_diff < np.std(highs) * 0.3:  # è‚©éƒ¨ç›¸ä¼¼åº¦æ£€æŸ¥
                        # è®¡ç®—é¢ˆçº¿
                        left_low = np.min(lows[left:head])
                        right_low = np.min(lows[head:right])
                        neckline = np.mean([left_low, right_low])
                        
                        # æ£€æŸ¥é¢ˆçº¿çªç ´
                        recent_closes = closes[-3:]
                        neckline_break = np.min(recent_closes) < neckline
                        
                        if neckline_break:
                            # è®¡ç®—ç½®ä¿¡åº¦
                            confidence = max(0.5, 0.85 - shoulder_diff / highs[head])
                            confidence *= shoulder_similarity  # è‚©éƒ¨ç›¸ä¼¼åº¦åŠ æˆ
                            
                            # æ£€æŸ¥æˆäº¤é‡ç¡®è®¤
                            volume_confirmation = self._check_volume_confirmation(closes)
                            confidence *= volume_confirmation
                            
                            signal = PatternSignal(
                                type=PatternType.HEAD_SHOULDER_BEAR,
                                confidence=min(1.0, confidence),
                                details={
                                    'neckline': float(neckline),
                                    'peaks': [int(left), int(head), int(right)],
                                    'head_height': float(highs[head]),
                                    'left_shoulder': float(highs[left]),
                                    'right_shoulder': float(highs[right]),
                                    'shoulder_similarity': float(shoulder_similarity),
                                    'neckline_break_confirmed': neckline_break
                                }
                            )
                            
                            signals.append(signal)
            
            # æ£€æµ‹å€’å¤´è‚©ï¼ˆå¤´è‚©åº•ï¼‰
            valley_signals = self._detect_inverse_head_shoulder(lows, highs, closes)
            signals.extend(valley_signals)
            
        except Exception as e:
            self.logger.error(f"æ£€æµ‹å¤´è‚©å½¢æ€å¤±è´¥: {e}")
        
        return signals
    
    def _detect_inverse_head_shoulder(self, lows: np.ndarray, highs: np.ndarray,
                                    closes: np.ndarray) -> List[PatternSignal]:
        """
        æ£€æµ‹å€’å¤´è‚©å½¢æ€ï¼ˆå¤´è‚©åº•ï¼‰
        
        Args:
            lows: æœ€ä½ä»·æ•°ç»„
            highs: æœ€é«˜ä»·æ•°ç»„
            closes: æ”¶ç›˜ä»·æ•°ç»„
            
        Returns:
            å€’å¤´è‚©å½¢æ€ä¿¡å·åˆ—è¡¨
        """
        signals = []
        
        try:
            # æ£€æµ‹è°·å€¼
            valleys_idx, _ = find_peaks(
                -lows,
                distance=self.min_distance,
                prominence=self.prominence_mult * np.std(lows)
            )
            
            if len(valleys_idx) >= 3:
                # å–æœ€è¿‘çš„ä¸‰ä¸ªè°·å€¼
                left, head, right = valleys_idx[-3:]
                
                # éªŒè¯å€’å¤´è‚©å½¢æ€ï¼ˆå¤´åº”è¯¥æ˜¯æœ€ä½ç‚¹ï¼‰
                if (lows[head] < lows[left] and 
                    lows[head] < lows[right]):
                    
                    # è®¡ç®—è‚©éƒ¨ç›¸ä¼¼åº¦
                    shoulder_diff = abs(lows[left] - lows[right])
                    shoulder_similarity = 1.0 - (shoulder_diff / abs(lows[head]))
                    
                    if shoulder_diff < np.std(lows) * 0.3:
                        # è®¡ç®—é¢ˆçº¿ï¼ˆé˜»åŠ›çº¿ï¼‰
                        left_high = np.max(highs[left:head])
                        right_high = np.max(highs[head:right])
                        neckline = np.mean([left_high, right_high])
                        
                        # æ£€æŸ¥é¢ˆçº¿çªç ´ï¼ˆå‘ä¸Šçªç ´ï¼‰
                        recent_closes = closes[-3:]
                        neckline_break = np.max(recent_closes) > neckline
                        
                        if neckline_break:
                            confidence = max(0.5, 0.85 - shoulder_diff / abs(lows[head]))
                            confidence *= shoulder_similarity
                            
                            signal = PatternSignal(
                                type=PatternType.HEAD_SHOULDER_BULL,
                                confidence=min(1.0, confidence),
                                details={
                                    'neckline': float(neckline),
                                    'valleys': [int(left), int(head), int(right)],
                                    'head_depth': float(lows[head]),
                                    'left_shoulder': float(lows[left]),
                                    'right_shoulder': float(lows[right]),
                                    'shoulder_similarity': float(shoulder_similarity),
                                    'neckline_break_confirmed': neckline_break
                                }
                            )
                            
                            signals.append(signal)
                            
        except Exception as e:
            self.logger.error(f"æ£€æµ‹å€’å¤´è‚©å½¢æ€å¤±è´¥: {e}")
        
        return signals
    
    def _detect_convergence_triangle_pattern(self, opens: np.ndarray, highs: np.ndarray,
                                           lows: np.ndarray, closes: np.ndarray) -> List[PatternSignal]:
        """
        æ£€æµ‹æ”¶æ•›ä¸‰è§’å½¢å½¢æ€ - ä½¿ç”¨np.polyfit
        
        Args:
            opens, highs, lows, closes: OHLCæ•°æ®
            
        Returns:
            æ”¶æ•›ä¸‰è§’å½¢ä¿¡å·åˆ—è¡¨
        """
        signals = []
        
        try:
            x = np.arange(len(highs))
            
            # ä½¿ç”¨çº¿æ€§å›å½’æ‹Ÿåˆè¶‹åŠ¿çº¿
            high_slope, high_inter = np.polyfit(x, highs, 1)
            low_slope, low_inter = np.polyfit(x, lows, 1)
            
            # æ£€æŸ¥æ”¶æ•›æ¡ä»¶ï¼šä¸Šé™ä¸‹å‡
            if high_slope < 0 and low_slope > 0:
                # è®¡ç®—æ”¶æ•›ç‚¹
                convergence_point = (high_inter - low_inter) / (low_slope - high_slope)
                
                # éªŒè¯æ”¶æ•›ç‚¹çš„åˆç†æ€§
                if 0 < convergence_point < len(highs) * 2:
                    # æ£€æŸ¥æ³¢åŠ¨æ”¶çª„
                    recent_vol = np.mean(highs[-3:] - lows[-3:])
                    avg_vol = np.mean(highs - lows)
                    
                    if recent_vol < avg_vol * 0.7:  # æ³¢åŠ¨æ”¶çª„ç¡®è®¤
                        # è®¡ç®—ç½®ä¿¡åº¦
                        slope_strength = abs(high_slope) + abs(low_slope)
                        confidence = min(1.0, 0.75 + slope_strength * 0.1)
                        
                        # ç¡®å®šçªç ´æ–¹å‘
                        last_close = closes[-1]
                        last_open = opens[-1]
                        
                        pattern_type = (PatternType.CONVERGENCE_TRIANGLE_BULL 
                                      if last_close > last_open 
                                      else PatternType.CONVERGENCE_TRIANGLE_BEAR)
                        
                        # å¢å¼ºç½®ä¿¡åº¦è®¡ç®—
                        confidence = self._enhance_triangle_confidence(
                            highs, lows, closes, confidence, convergence_point
                        )
                        
                        signal = PatternSignal(
                            type=pattern_type,
                            confidence=confidence,
                            details={
                                'convergence_point': float(convergence_point),
                                'high_slope': float(high_slope),
                                'low_slope': float(low_slope),
                                'high_intercept': float(high_inter),
                                'low_intercept': float(low_inter),
                                'volume_compression': float(recent_vol / avg_vol),
                                'slope_strength': float(slope_strength)
                            }
                        )
                        
                        signals.append(signal)
                        
        except Exception as e:
            self.logger.error(f"æ£€æµ‹æ”¶æ•›ä¸‰è§’å½¢å¤±è´¥: {e}")
        
        return signals
    
    def _enhance_triangle_confidence(self, highs: np.ndarray, lows: np.ndarray,
                                   closes: np.ndarray, base_confidence: float,
                                   convergence_point: float) -> float:
        """
        å¢å¼ºä¸‰è§’å½¢å½¢æ€ç½®ä¿¡åº¦
        
        Args:
            highs, lows, closes: ä»·æ ¼æ•°æ®
            base_confidence: åŸºç¡€ç½®ä¿¡åº¦
            convergence_point: æ”¶æ•›ç‚¹
            
        Returns:
            å¢å¼ºåçš„ç½®ä¿¡åº¦
        """
        try:
            # è®¡ç®—è¶‹åŠ¿çº¿æ‹Ÿåˆåº¦
            x = np.arange(len(highs))
            high_slope, high_inter = np.polyfit(x, highs, 1)
            low_slope, low_inter = np.polyfit(x, lows, 1)
            
            # è®¡ç®—RÂ²å€¼
            high_trend = high_slope * x + high_inter
            low_trend = low_slope * x + low_inter
            
            high_r2 = 1 - np.sum((highs - high_trend)**2) / np.sum((highs - np.mean(highs))**2)
            low_r2 = 1 - np.sum((lows - low_trend)**2) / np.sum((lows - np.mean(lows))**2)
            
            avg_r2 = (high_r2 + low_r2) / 2
            
            # è®¡ç®—è·ç¦»æ”¶æ•›ç‚¹çš„è¿œè¿‘
            distance_factor = min(1.0, convergence_point / len(highs))
            
            # è®¡ç®—æ³¢åŠ¨æ€§å‹ç¼©ç¨‹åº¦
            early_vol = np.mean(highs[:len(highs)//2] - lows[:len(lows)//2])
            late_vol = np.mean(highs[len(highs)//2:] - lows[len(lows)//2:])
            compression_ratio = late_vol / early_vol if early_vol > 0 else 1
            
            # ç»¼åˆè°ƒæ•´ç½®ä¿¡åº¦
            r2_bonus = max(0, avg_r2 - 0.5) * 0.2
            distance_bonus = (1 - distance_factor) * 0.1
            compression_bonus = max(0, 1 - compression_ratio) * 0.1
            
            enhanced_confidence = min(1.0, 
                base_confidence + r2_bonus + distance_bonus + compression_bonus
            )
            
            return enhanced_confidence
            
        except Exception as e:
            self.logger.error(f"å¢å¼ºä¸‰è§’å½¢ç½®ä¿¡åº¦å¤±è´¥: {e}")
            return base_confidence
    
    def _calculate_trend_strength(self, closes: np.ndarray) -> float:
        """
        è®¡ç®—è¶‹åŠ¿å¼ºåº¦
        
        Args:
            closes: æ”¶ç›˜ä»·æ•°ç»„
            
        Returns:
            è¶‹åŠ¿å¼ºåº¦ (-1åˆ°1)
        """
        try:
            if len(closes) < 10:
                return 0.0
            
            # çŸ­æœŸå’Œé•¿æœŸç§»åŠ¨å¹³å‡
            short_ma = np.mean(closes[-5:])
            long_ma = np.mean(closes[-10:])
            
            # è®¡ç®—è¶‹åŠ¿å¼ºåº¦
            trend_strength = (short_ma - long_ma) / long_ma if long_ma > 0 else 0
            
            # æ ‡å‡†åŒ–åˆ°[-1, 1]èŒƒå›´
            return np.clip(trend_strength * 10, -1, 1)
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—è¶‹åŠ¿å¼ºåº¦å¤±è´¥: {e}")
            return 0.0
    
    def _check_volume_confirmation(self, closes: np.ndarray) -> float:
        """
        æ£€æŸ¥æˆäº¤é‡ç¡®è®¤ï¼ˆç®€åŒ–å®ç°ï¼‰
        
        Args:
            closes: æ”¶ç›˜ä»·æ•°ç»„
            
        Returns:
            æˆäº¤é‡ç¡®è®¤å› å­ (0.8-1.2)
        """
        try:
            # è¿™é‡Œæ˜¯ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥ä½¿ç”¨çœŸå®æˆäº¤é‡æ•°æ®
            # åŸºäºä»·æ ¼å˜åŒ–æ¨¡æ‹Ÿæˆäº¤é‡ç¡®è®¤
            price_volatility = np.std(closes[-5:]) / np.mean(closes[-5:])
            
            # é«˜æ³¢åŠ¨æ€§å‡è®¾æˆäº¤é‡æ”¾å¤§
            if price_volatility > 0.02:
                return 1.1
            elif price_volatility < 0.01:
                return 0.9
            else:
                return 1.0
                
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥æˆäº¤é‡ç¡®è®¤å¤±è´¥: {e}")
            return 1.0
    
    def analyze_market_structure(self, highs: np.ndarray, lows: np.ndarray, 
                               closes: np.ndarray, vol_factor: float = 0.0) -> Dict[str, Any]:
        """
        ç»¼åˆåˆ†æå¸‚åœºç»“æ„
        
        Args:
            highs: æœ€é«˜ä»·æ•°ç»„
            lows: æœ€ä½ä»·æ•°ç»„
            closes: æ”¶ç›˜ä»·æ•°ç»„
            vol_factor: æ³¢åŠ¨æ€§å› å­
            
        Returns:
            å¸‚åœºç»“æ„åˆ†æç»“æœ
        """
        try:
            # æ£€æµ‹èƒŒç¦»ä¿¡å·
            divergence_signals = self.detect_divergence(highs, lows, closes, vol_factor)
            
            # æ£€æµ‹å½¢æ€ä¿¡å·
            opens = closes - 0.5  # ç®€åŒ–å¼€ç›˜ä»·
            pattern_signals = self.detect_pattern(opens, highs, lows, closes)
            
            # åˆ†æä¿¡å·è´¨é‡
            signal_quality = self._analyze_signal_quality(divergence_signals, pattern_signals)
            
            # ç»¼åˆè¯„åˆ†
            overall_score = self._calculate_overall_score(divergence_signals, pattern_signals)
            
            analysis_result = {
                'divergence_signals': [signal.to_dict() for signal in divergence_signals],
                'pattern_signals': [signal.to_dict() for signal in pattern_signals],
                'signal_quality': signal_quality,
                'overall_score': overall_score,
                'market_condition': self._determine_market_condition(overall_score),
                'recommendation': self._generate_recommendation(divergence_signals, pattern_signals),
                'timestamp': datetime.now().isoformat()
            }
            
            # è®°å½•åˆ°å†å²
            self._add_to_history(analysis_result)
            
            return analysis_result
            
        except Exception as e:
            self.logger.error(f"å¸‚åœºç»“æ„åˆ†æå¤±è´¥: {e}")
            return {
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def _analyze_signal_quality(self, divergence_signals: List[DivergenceSignal],
                              pattern_signals: List[PatternSignal]) -> Dict[str, Any]:
        """
        åˆ†æä¿¡å·è´¨é‡
        
        Args:
            divergence_signals: èƒŒç¦»ä¿¡å·åˆ—è¡¨
            pattern_signals: å½¢æ€ä¿¡å·åˆ—è¡¨
            
        Returns:
            ä¿¡å·è´¨é‡åˆ†æç»“æœ
        """
        try:
            total_signals = len(divergence_signals) + len(pattern_signals)
            
            if total_signals == 0:
                return {
                    'total_signals': 0,
                    'high_confidence_ratio': 0.0,
                    'avg_confidence': 0.0,
                    'signal_consistency': 0.0
                }
            
            # è®¡ç®—é«˜ç½®ä¿¡åº¦ä¿¡å·æ¯”ä¾‹
            high_conf_count = 0
            total_confidence = 0
            
            for signal in divergence_signals:
                if signal.confidence > 0.7:
                    high_conf_count += 1
                total_confidence += signal.confidence
            
            for signal in pattern_signals:
                if signal.confidence > 0.7:
                    high_conf_count += 1
                total_confidence += signal.confidence
            
            high_confidence_ratio = high_conf_count / total_signals
            avg_confidence = total_confidence / total_signals
            
            # è®¡ç®—ä¿¡å·ä¸€è‡´æ€§
            signal_consistency = self._calculate_signal_consistency(
                divergence_signals, pattern_signals
            )
            
            return {
                'total_signals': total_signals,
                'high_confidence_ratio': high_confidence_ratio,
                'avg_confidence': avg_confidence,
                'signal_consistency': signal_consistency,
                'divergence_count': len(divergence_signals),
                'pattern_count': len(pattern_signals)
            }
            
        except Exception as e:
            self.logger.error(f"åˆ†æä¿¡å·è´¨é‡å¤±è´¥: {e}")
            return {}
    
    def _calculate_signal_consistency(self, divergence_signals: List[DivergenceSignal],
                                    pattern_signals: List[PatternSignal]) -> float:
        """
        è®¡ç®—ä¿¡å·ä¸€è‡´æ€§
        
        Args:
            divergence_signals: èƒŒç¦»ä¿¡å·åˆ—è¡¨
            pattern_signals: å½¢æ€ä¿¡å·åˆ—è¡¨
            
        Returns:
            ä¿¡å·ä¸€è‡´æ€§åˆ†æ•° (0-1)
        """
        try:
            if not divergence_signals and not pattern_signals:
                return 0.0
            
            # ç»Ÿè®¡çœ‹æ¶¨å’Œçœ‹è·Œä¿¡å·
            bullish_count = 0
            bearish_count = 0
            
            for signal in divergence_signals:
                if signal.type == DivergenceType.BULLISH:
                    bullish_count += 1
                else:
                    bearish_count += 1
            
            for signal in pattern_signals:
                if 'BULL' in signal.type.value:
                    bullish_count += 1
                else:
                    bearish_count += 1
            
            total_count = bullish_count + bearish_count
            
            if total_count == 0:
                return 0.0
            
            # è®¡ç®—ä¸€è‡´æ€§ï¼šä¸»å¯¼æ–¹å‘çš„ä¿¡å·å æ¯”
            dominant_ratio = max(bullish_count, bearish_count) / total_count
            
            return dominant_ratio
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—ä¿¡å·ä¸€è‡´æ€§å¤±è´¥: {e}")
            return 0.0
    
    def _calculate_overall_score(self, divergence_signals: List[DivergenceSignal],
                               pattern_signals: List[PatternSignal]) -> float:
        """
        è®¡ç®—ç»¼åˆè¯„åˆ†
        
        Args:
            divergence_signals: èƒŒç¦»ä¿¡å·åˆ—è¡¨
            pattern_signals: å½¢æ€ä¿¡å·åˆ—è¡¨
            
        Returns:
            ç»¼åˆè¯„åˆ† (0-100)
        """
        try:
            if not divergence_signals and not pattern_signals:
                return 50.0  # ä¸­æ€§
            
            total_score = 0
            total_weight = 0
            
            # èƒŒç¦»ä¿¡å·è¯„åˆ†ï¼ˆæƒé‡0.6ï¼‰
            for signal in divergence_signals:
                signal_score = signal.confidence * 100
                if signal.type == DivergenceType.BULLISH:
                    signal_score = signal_score
                else:
                    signal_score = 100 - signal_score
                
                total_score += signal_score * 0.6
                total_weight += 0.6
            
            # å½¢æ€ä¿¡å·è¯„åˆ†ï¼ˆæƒé‡0.4ï¼‰
            for signal in pattern_signals:
                signal_score = signal.confidence * 100
                if 'BULL' in signal.type.value:
                    signal_score = signal_score
                else:
                    signal_score = 100 - signal_score
                
                total_score += signal_score * 0.4
                total_weight += 0.4
            
            if total_weight == 0:
                return 50.0
            
            overall_score = total_score / total_weight
            
            return np.clip(overall_score, 0, 100)
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—ç»¼åˆè¯„åˆ†å¤±è´¥: {e}")
            return 50.0
    
    def _determine_market_condition(self, overall_score: float) -> str:
        """
        ç¡®å®šå¸‚åœºçŠ¶æ€
        
        Args:
            overall_score: ç»¼åˆè¯„åˆ†
            
        Returns:
            å¸‚åœºçŠ¶æ€æè¿°
        """
        if overall_score >= 75:
            return "å¼ºçƒˆçœ‹æ¶¨"
        elif overall_score >= 60:
            return "çœ‹æ¶¨"
        elif overall_score >= 40:
            return "ä¸­æ€§"
        elif overall_score >= 25:
            return "çœ‹è·Œ"
        else:
            return "å¼ºçƒˆçœ‹è·Œ"
    
    def _generate_recommendation(self, divergence_signals: List[DivergenceSignal],
                               pattern_signals: List[PatternSignal]) -> str:
        """
        ç”Ÿæˆäº¤æ˜“å»ºè®®
        
        Args:
            divergence_signals: èƒŒç¦»ä¿¡å·åˆ—è¡¨
            pattern_signals: å½¢æ€ä¿¡å·åˆ—è¡¨
            
        Returns:
            äº¤æ˜“å»ºè®®
        """
        try:
            if not divergence_signals and not pattern_signals:
                return "æ— æ˜ç¡®ä¿¡å·ï¼Œå»ºè®®è§‚æœ›"
            
            # ç»Ÿè®¡é«˜è´¨é‡ä¿¡å·
            high_quality_bullish = 0
            high_quality_bearish = 0
            
            for signal in divergence_signals:
                if signal.confidence > 0.7:
                    if signal.type == DivergenceType.BULLISH:
                        high_quality_bullish += 1
                    else:
                        high_quality_bearish += 1
            
            for signal in pattern_signals:
                if signal.confidence > 0.7:
                    if 'BULL' in signal.type.value:
                        high_quality_bullish += 1
                    else:
                        high_quality_bearish += 1
            
            if high_quality_bullish > high_quality_bearish:
                return f"å»ºè®®çœ‹æ¶¨ï¼Œå‘ç°{high_quality_bullish}ä¸ªé«˜è´¨é‡çœ‹æ¶¨ä¿¡å·"
            elif high_quality_bearish > high_quality_bullish:
                return f"å»ºè®®çœ‹è·Œï¼Œå‘ç°{high_quality_bearish}ä¸ªé«˜è´¨é‡çœ‹è·Œä¿¡å·"
            else:
                return "ä¿¡å·æ··åˆï¼Œå»ºè®®è°¨æ…æ“ä½œ"
                
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆäº¤æ˜“å»ºè®®å¤±è´¥: {e}")
            return "åˆ†æå‡ºé”™ï¼Œå»ºè®®è§‚æœ›"
    
    def _add_to_history(self, analysis_result: Dict[str, Any]):
        """
        æ·»åŠ åˆ†æç»“æœåˆ°å†å²è®°å½•
        
        Args:
            analysis_result: åˆ†æç»“æœ
        """
        try:
            self.signal_history.append(analysis_result)
            
            # é™åˆ¶å†å²è®°å½•å¤§å°
            if len(self.signal_history) > self.max_history:
                self.signal_history = self.signal_history[-self.max_history//2:]
                
        except Exception as e:
            self.logger.error(f"æ·»åŠ å†å²è®°å½•å¤±è´¥: {e}")
    
    def get_detection_statistics(self) -> Dict[str, Any]:
        """
        è·å–æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            total_detections = self.detection_stats['total_detections']
            
            if total_detections == 0:
                return {
                    'total_detections': 0,
                    'detection_rates': {},
                    'accuracy_metrics': {}
                }
            
            return {
                'total_detections': total_detections,
                'divergence_count': self.detection_stats['divergence_count'],
                'pattern_count': self.detection_stats['pattern_count'],
                'high_confidence_signals': self.detection_stats['high_confidence_signals'],
                'detection_rates': {
                    'divergence_rate': self.detection_stats['divergence_count'] / total_detections,
                    'pattern_rate': self.detection_stats['pattern_count'] / total_detections,
                    'high_confidence_rate': self.detection_stats['high_confidence_signals'] / total_detections
                },
                'accuracy_metrics': {
                    'false_positive_rate': self.detection_stats['false_positive_rate'],
                    'signal_history_size': len(self.signal_history)
                },
                'configuration': {
                    'lookback_period': self.lookback,
                    'min_distance': self.min_distance,
                    'prominence_multiplier': self.prominence_mult,
                    'supported_patterns': self.morph_patterns
                }
            }
            
        except Exception as e:
            self.logger.error(f"è·å–æ£€æµ‹ç»Ÿè®¡å¤±è´¥: {e}")
            return {}
    
    def reset_statistics(self):
        """
        é‡ç½®æ£€æµ‹ç»Ÿè®¡
        """
        try:
            self.detection_stats = {
                'total_detections': 0,
                'divergence_count': 0,
                'pattern_count': 0,
                'high_confidence_signals': 0,
                'false_positive_rate': 0.0
            }
            
            self.signal_history.clear()
            
            self.logger.info("æ£€æµ‹ç»Ÿè®¡å·²é‡ç½®")
            
        except Exception as e:
            self.logger.error(f"é‡ç½®æ£€æµ‹ç»Ÿè®¡å¤±è´¥: {e}")
    
    def update_configuration(self, **kwargs):
        """
        æ›´æ–°æ£€æµ‹é…ç½®
        
        Args:
            **kwargs: é…ç½®å‚æ•°
        """
        try:
            if 'lookback' in kwargs:
                self.lookback = kwargs['lookback']
            
            if 'min_distance' in kwargs:
                self.min_distance = kwargs['min_distance']
            
            if 'prominence_mult' in kwargs:
                self.prominence_mult = kwargs['prominence_mult']
            
            if 'min_consecutive' in kwargs:
                self.min_consecutive = kwargs['min_consecutive']
            
            if 'morph_patterns' in kwargs:
                self.morph_patterns = kwargs['morph_patterns']
            
            self.logger.info(f"æ£€æµ‹é…ç½®å·²æ›´æ–°: {kwargs}")
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°æ£€æµ‹é…ç½®å¤±è´¥: {e}")

    def detect_patterns(self, df: pd.DataFrame, symbol: str = "BTCUSDT") -> List[Dict]:
        """æ‰¹é‡æ£€æµ‹å½¢æ€çš„ç®€åŒ–æ¥å£"""
        try:
            if len(df) < 20:
                return []
                
            # è½¬æ¢æ•°æ®
            opens = df['open'].astype(float).values
            highs = df['high'].astype(float).values  
            lows = df['low'].astype(float).values
            closes = df['close'].astype(float).values
            
            # æ£€æµ‹å•ä¸ªå½¢æ€
            pattern = self.detect_pattern(opens, highs, lows, closes)
            
            # åŒ…è£…æˆåˆ—è¡¨æ ¼å¼
            results = []
            if pattern and pattern.get('pattern_type') != 'UNKNOWN':
                results.append({
                    'symbol': symbol,
                    'pattern_type': pattern.get('pattern_type', 'UNKNOWN'),
                    'confidence': pattern.get('confidence', 0.0),
                    'timestamp': df.index[-1] if hasattr(df, 'index') else len(df)-1
                })
            
            return results
            
        except Exception as e:
            self.logger.error(f"æ‰¹é‡å½¢æ€æ£€æµ‹å¤±è´¥: {e}")
            return []


# æµ‹è¯•å‡½æ•°
def test_enhanced_pattern_detector():
    """
    æµ‹è¯•å¢å¼ºå½¢æ€æ£€æµ‹å™¨
    """
    try:
        # åˆ›å»ºæ¨¡æ‹Ÿé…ç½®
        from config.config_manager import ConfigManager
        config = ConfigManager()
        
        # åˆ›å»ºæ£€æµ‹å™¨
        detector = EnhancedPatternDetector(config)
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        np.random.seed(42)
        length = 100
        
        base_price = 100
        trend = np.linspace(0, 10, length)
        noise = np.random.normal(0, 1, length)
        
        closes = base_price + trend + noise
        highs = closes + np.abs(np.random.normal(0, 0.5, length))
        lows = closes - np.abs(np.random.normal(0, 0.5, length))
        opens = closes - np.random.normal(0, 0.2, length)
        
        # æµ‹è¯•å¸‚åœºç»“æ„åˆ†æ
        analysis = detector.analyze_market_structure(highs, lows, closes)
        
        print("=== å¢å¼ºå½¢æ€æ£€æµ‹å™¨æµ‹è¯•ç»“æœ ===")
        print(f"æ£€æµ‹åˆ°èƒŒç¦»ä¿¡å·: {len(analysis.get('divergence_signals', []))}")
        print(f"æ£€æµ‹åˆ°å½¢æ€ä¿¡å·: {len(analysis.get('pattern_signals', []))}")
        print(f"ç»¼åˆè¯„åˆ†: {analysis.get('overall_score', 0):.2f}")
        print(f"å¸‚åœºçŠ¶æ€: {analysis.get('market_condition', 'Unknown')}")
        print(f"äº¤æ˜“å»ºè®®: {analysis.get('recommendation', 'Unknown')}")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = detector.get_detection_statistics()
        print(f"\næ£€æµ‹ç»Ÿè®¡: {stats}")
        
        return True
        
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    test_enhanced_pattern_detector() 