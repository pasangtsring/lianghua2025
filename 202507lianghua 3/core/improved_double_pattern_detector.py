"""
ğŸ†• ä»»åŠ¡4.1: æ”¹è¿›ç‰ˆWåº•/åŒé¡¶æ£€æµ‹å™¨
åŸºäºå¤§ç¥ç®—æ³•çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œä¿®å¤å…³é”®bugï¼Œé€‚é…15åˆ†é’Ÿé«˜é¢‘äº¤æ˜“

ä¸»è¦æ”¹è¿›ï¼š
1. ä¿®å¤ä¸­é—´å³°/è°·éªŒè¯é€»è¾‘çš„å…³é”®bug
2. å¢å¼ºç¨³å¥æ€§ï¼Œå¤„ç†NaNå€¼å’Œè¾¹ç•Œæƒ…å†µ  
3. ä¼˜åŒ–å‚æ•°é€‚é…15åˆ†é’ŸKçº¿æ•°æ®
4. ç®€åŒ–ç½®ä¿¡åº¦è®¡ç®—ï¼Œæé«˜å‡†ç¡®æ€§
"""

import numpy as np
from scipy.signal import find_peaks
import talib as ta
from typing import List, Tuple, Optional, Dict, Any, Union
from dataclasses import dataclass, field
from datetime import datetime
import logging
from enum import Enum

from utils.logger import get_logger

class DoublePatternType(Enum):
    """åŒé‡å½¢æ€ç±»å‹æšä¸¾"""
    DOUBLE_BOTTOM_BULL = "double_bottom_bull"  # Wåº•çœ‹æ¶¨
    DOUBLE_TOP_BEAR = "double_top_bear"        # åŒé¡¶çœ‹è·Œ

@dataclass  
class PatternSignal:
    """å½¢æ€ä¿¡å·æ•°æ®ç»“æ„"""
    type: DoublePatternType
    confidence: float
    entry_price: float
    target_price: float
    stop_loss: float
    formation_bars: int
    volume_ratio: float
    similarity_score: float
    rsi_confirmation: float
    timestamp: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'type': self.type.value,
            'confidence': self.confidence,
            'entry_price': self.entry_price,
            'target_price': self.target_price, 
            'stop_loss': self.stop_loss,
            'formation_bars': self.formation_bars,
            'volume_ratio': self.volume_ratio,
            'similarity_score': self.similarity_score,
            'rsi_confirmation': self.rsi_confirmation,
            'timestamp': self.timestamp.isoformat(),
            'metadata': self.metadata
        }

class ImprovedDoublePatternDetector:
    """
    ğŸ”§ æ”¹è¿›ç‰ˆWåº•/åŒé¡¶å½¢æ€æ£€æµ‹å™¨
    
    ä¸»è¦æ”¹è¿›ï¼š
    1. âœ… ä¿®å¤ä¸­é—´å³°/è°·éªŒè¯çš„å…³é”®é€»è¾‘é”™è¯¯
    2. âœ… å¢å¼ºæ•°æ®ç¨³å¥æ€§å¤„ç†ï¼ˆNaNã€è¾¹ç•Œæƒ…å†µï¼‰
    3. âœ… ä¼˜åŒ–é«˜é¢‘äº¤æ˜“å‚æ•°ï¼ˆ15åˆ†é’ŸKçº¿é€‚é…ï¼‰
    4. âœ… ç®€åŒ–ç½®ä¿¡åº¦è®¡ç®—é€»è¾‘
    """
    
    def __init__(
        self,
        min_bars: int = 10,          # æœ€å°å½¢æ€å‘¨æœŸï¼ˆé™ä½ä¸º10ï¼Œæé«˜æ•æ„Ÿåº¦ï¼‰
        max_bars: int = 50,          # æœ€å¤§å½¢æ€å‘¨æœŸï¼ˆå¢åŠ ä¸º50ï¼Œé€‚é…æ›´å¤šå½¢æ€ï¼‰
        similarity_thresh: float = 0.1,   # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆæ”¾å®½åˆ°10%ï¼Œé¿å…è¿‡ä¸¥ï¼‰
        volume_mult: float = 1.2,    # æˆäº¤é‡ç¡®è®¤å€æ•°ï¼ˆé™ä½åˆ°1.2ï¼‰
        rsi_bull_thresh: float = 50, # RSIçœ‹æ¶¨é˜ˆå€¼ï¼ˆè®¾ä¸ºä¸­æ€§50ï¼‰
        rsi_bear_thresh: float = 50, # RSIçœ‹è·Œé˜ˆå€¼ï¼ˆè®¾ä¸ºä¸­æ€§50ï¼‰
        min_confidence: float = 0.5  # æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆé™ä½åˆ°0.5ï¼‰
    ):
        self.min_bars = min_bars
        self.max_bars = max_bars  
        self.similarity_thresh = similarity_thresh
        self.volume_mult = volume_mult
        self.rsi_bull_thresh = rsi_bull_thresh
        self.rsi_bear_thresh = rsi_bear_thresh
        self.min_confidence = min_confidence
        
        self.logger = get_logger(__name__)
        
        # æ—¥å¿—è®°å½•å‚æ•°è®¾ç½®
        self.logger.info(f"ğŸ”§ åˆå§‹åŒ–æ”¹è¿›ç‰ˆåŒé‡å½¢æ€æ£€æµ‹å™¨:")
        self.logger.info(f"   ğŸ“Š å½¢æ€å‘¨æœŸ: {min_bars}-{max_bars} æ ¹Kçº¿")
        self.logger.info(f"   ğŸ“ ç›¸ä¼¼åº¦é˜ˆå€¼: {similarity_thresh*100:.1f}%")
        self.logger.info(f"   ğŸ“¦ æˆäº¤é‡å€æ•°: {volume_mult}x")
        self.logger.info(f"   ğŸ“ˆ RSIé˜ˆå€¼: çœ‹æ¶¨<{rsi_bull_thresh}, çœ‹è·Œ>{rsi_bear_thresh}")
        self.logger.info(f"   ğŸ¯ æœ€å°ç½®ä¿¡åº¦: {min_confidence}")

    def _safe_rsi_calculation(self, closes: np.ndarray, period: int = 14) -> np.ndarray:
        """
        ğŸ›¡ï¸ å®‰å…¨çš„RSIè®¡ç®—ï¼Œå¤„ç†NaNå€¼å’Œæ•°æ®ä¸è¶³æƒ…å†µ
        è¿™æ˜¯å¯¹åŸç®—æ³•çš„é‡è¦æ”¹è¿›ï¼Œé¿å…å› æ•°æ®é—®é¢˜å¯¼è‡´çš„è®¡ç®—å¤±è´¥
        """
        try:
            if len(closes) < period:
                # æ•°æ®ä¸è¶³æ—¶è¿”å›ä¸­æ€§å€¼50
                return np.full(len(closes), 50.0)
            
            rsi = ta.RSI(closes.astype(float), timeperiod=period)
            
            # å¤„ç†NaNå€¼ï¼šå‰é¢çš„NaNç”¨50å¡«å……ï¼Œé¿å…è®¡ç®—é”™è¯¯
            if np.isnan(rsi).any():
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ªéNaNçš„ä½ç½®
                first_valid = period - 1
                rsi[:first_valid] = 50.0  # NaNéƒ¨åˆ†å¡«å……50ï¼ˆä¸­æ€§ï¼‰
                
                # å¤„ç†å¯èƒ½çš„å…¶ä»–NaNå€¼
                rsi = np.nan_to_num(rsi, nan=50.0)
            
            return rsi
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ RSIè®¡ç®—å¼‚å¸¸: {e}, è¿”å›ä¸­æ€§å€¼")
            return np.full(len(closes), 50.0)

    def detect_double_bottom(
        self, 
        highs: np.ndarray, 
        lows: np.ndarray, 
        closes: np.ndarray, 
        volumes: np.ndarray
    ) -> Optional[PatternSignal]:
        """
        ğŸ” æ£€æµ‹Wåº•ï¼ˆåŒåº•ï¼‰å½¢æ€
        
        å…³é”®æ”¹è¿›ï¼šä¿®å¤äº†åŸç®—æ³•ä¸­é—´å³°éªŒè¯çš„ä¸¥é‡é€»è¾‘é”™è¯¯
        """
        try:
            if len(lows) < self.min_bars:
                return None
            
            # 1. å¯»æ‰¾ä½ç‚¹ï¼ˆè°·å€¼ï¼‰
            valley_indices, _ = find_peaks(-lows, distance=max(5, self.min_bars//3))
            
            if len(valley_indices) < 2:
                return None
            
            # 2. æ£€æŸ¥æœ€åä¸¤ä¸ªä½ç‚¹ä½œä¸ºåŒåº•å€™é€‰
            if len(valley_indices) >= 2:
                left_valley_idx = valley_indices[-2]  # å·¦åº•
                right_valley_idx = valley_indices[-1] # å³åº•
            else:
                return None
            
            # 3. éªŒè¯å½¢æ€å‘¨æœŸåˆç†æ€§
            formation_bars = right_valley_idx - left_valley_idx
            if formation_bars < self.min_bars or formation_bars > self.max_bars:
                return None
            
            # 4. æ£€æŸ¥åº•éƒ¨ç›¸ä¼¼æ€§
            left_low = lows[left_valley_idx]
            right_low = lows[right_valley_idx]
            similarity = abs(left_low - right_low) / min(left_low, right_low)
            
            if similarity > self.similarity_thresh:
                return None
            
            # 5. ğŸ”§ å…³é”®ä¿®å¤ï¼šæ­£ç¡®çš„ä¸­é—´å³°éªŒè¯é€»è¾‘
            # åŸç®—æ³•é”™è¯¯ï¼šä¸å…¨å±€æœ€é«˜ç‚¹æ¯”è¾ƒ â€”â€” if middle_peak < max(highs)
            # ä¿®å¤ç‰ˆæœ¬ï¼šæ‰¾åˆ°ä¸¤ä¸ªåº•éƒ¨ä¹‹é—´çš„å®é™…æœ€é«˜ç‚¹ä½œä¸ºé¢ˆçº¿
            middle_section = highs[left_valley_idx:right_valley_idx+1]
            middle_peak_relative_idx = np.argmax(middle_section)
            middle_peak_idx = left_valley_idx + middle_peak_relative_idx
            middle_peak = highs[middle_peak_idx]
            
            # ä¸­é—´å³°åº”è¯¥æ˜æ˜¾é«˜äºä¸¤ä¸ªåº•éƒ¨
            if middle_peak <= max(left_low, right_low) * 1.02:  # è‡³å°‘é«˜2%
                return None
            
            # 6. éªŒè¯çªç ´ç¡®è®¤ï¼ˆå½“å‰ä»·æ ¼çªç ´é¢ˆçº¿ï¼‰
            current_price = closes[-1]
            neckline = middle_peak
            
            if current_price <= neckline:
                return None  # è¿˜æœªçªç ´ï¼Œä¸äº§ç”Ÿä¿¡å·
            
            # 7. æˆäº¤é‡ç¡®è®¤
            recent_volume = np.mean(volumes[-5:])  # æœ€è¿‘5æ ¹Kçº¿å¹³å‡æˆäº¤é‡
            base_volume = np.mean(volumes[left_valley_idx:right_valley_idx+1])
            volume_ratio = recent_volume / base_volume if base_volume > 0 else 1.0
            
            # 8. RSIç¡®è®¤ï¼ˆä½¿ç”¨å®‰å…¨è®¡ç®—ï¼‰
            rsi_values = self._safe_rsi_calculation(closes)
            current_rsi = rsi_values[-1]
            
            # 9. è®¡ç®—ç½®ä¿¡åº¦ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œæ›´ç¨³å®šï¼‰
            confidence_factors = {
                'similarity': max(0, 1 - similarity / self.similarity_thresh) * 0.25,  # 25%æƒé‡
                'volume': min(volume_ratio / self.volume_mult, 1.0) * 0.25,           # 25%æƒé‡  
                'rsi': (1.0 if current_rsi < self.rsi_bull_thresh else 0.5) * 0.25,  # 25%æƒé‡
                'breakout': min((current_price - neckline) / neckline / 0.02, 1.0) * 0.25  # 25%æƒé‡
            }
            
            total_confidence = sum(confidence_factors.values())
            
            # 10. ç½®ä¿¡åº¦æ£€æŸ¥
            if total_confidence < self.min_confidence:
                return None
            
            # 11. è®¡ç®—äº¤æ˜“å‚æ•°
            entry_price = current_price
            height = neckline - max(left_low, right_low)  # å½¢æ€é«˜åº¦
            target_price = neckline + height              # ç›®æ ‡ä»·æ ¼
            stop_loss = min(left_low, right_low) * 0.98   # æ­¢æŸè®¾åœ¨æœ€ä½ç‚¹ä¸‹æ–¹2%
            
            # 12. åˆ›å»ºä¿¡å·
            signal = PatternSignal(
                type=DoublePatternType.DOUBLE_BOTTOM_BULL,
                confidence=total_confidence,
                entry_price=entry_price,
                target_price=target_price,
                stop_loss=stop_loss,
                formation_bars=formation_bars,
                volume_ratio=volume_ratio,
                similarity_score=1 - similarity,
                rsi_confirmation=current_rsi,
                metadata={
                    'left_valley_idx': int(left_valley_idx),
                    'right_valley_idx': int(right_valley_idx),
                    'middle_peak_idx': int(middle_peak_idx),
                    'neckline': float(neckline),
                    'confidence_breakdown': confidence_factors
                }
            )
            
            self.logger.info(f"âœ… æ£€æµ‹åˆ°Wåº•å½¢æ€: ç½®ä¿¡åº¦={total_confidence:.2f}, "
                           f"å½¢æ€å‘¨æœŸ={formation_bars}, ç›¸ä¼¼åº¦={1-similarity:.2f}")
            
            return signal
            
        except Exception as e:
            self.logger.error(f"âŒ Wåº•æ£€æµ‹å¼‚å¸¸: {e}")
            return None

    def detect_double_top(
        self, 
        highs: np.ndarray, 
        lows: np.ndarray, 
        closes: np.ndarray, 
        volumes: np.ndarray
    ) -> Optional[PatternSignal]:
        """
        ğŸ” æ£€æµ‹åŒé¡¶å½¢æ€
        
        è¿™æ˜¯Wåº•æ£€æµ‹çš„é•œåƒç‰ˆæœ¬ï¼Œåº”ç”¨ç›¸åŒçš„é€»è¾‘ä¿®å¤
        """
        try:
            if len(highs) < self.min_bars:
                return None
            
            # 1. å¯»æ‰¾é«˜ç‚¹ï¼ˆå³°å€¼ï¼‰
            peak_indices, _ = find_peaks(highs, distance=max(5, self.min_bars//3))
            
            if len(peak_indices) < 2:
                return None
            
            # 2. æ£€æŸ¥æœ€åä¸¤ä¸ªé«˜ç‚¹ä½œä¸ºåŒé¡¶å€™é€‰
            if len(peak_indices) >= 2:
                left_peak_idx = peak_indices[-2]   # å·¦é¡¶
                right_peak_idx = peak_indices[-1]  # å³é¡¶
            else:
                return None
            
            # 3. éªŒè¯å½¢æ€å‘¨æœŸåˆç†æ€§
            formation_bars = right_peak_idx - left_peak_idx
            if formation_bars < self.min_bars or formation_bars > self.max_bars:
                return None
            
            # 4. æ£€æŸ¥é¡¶éƒ¨ç›¸ä¼¼æ€§
            left_high = highs[left_peak_idx]
            right_high = highs[right_peak_idx]
            similarity = abs(left_high - right_high) / max(left_high, right_high)
            
            if similarity > self.similarity_thresh:
                return None
            
            # 5. ğŸ”§ å…³é”®ä¿®å¤ï¼šæ­£ç¡®çš„ä¸­é—´è°·éªŒè¯é€»è¾‘
            # æ‰¾åˆ°ä¸¤ä¸ªé¡¶éƒ¨ä¹‹é—´çš„å®é™…æœ€ä½ç‚¹ä½œä¸ºé¢ˆçº¿
            middle_section = lows[left_peak_idx:right_peak_idx+1]
            middle_valley_relative_idx = np.argmin(middle_section)
            middle_valley_idx = left_peak_idx + middle_valley_relative_idx
            middle_valley = lows[middle_valley_idx]
            
            # ä¸­é—´è°·åº”è¯¥æ˜æ˜¾ä½äºä¸¤ä¸ªé¡¶éƒ¨
            if middle_valley >= min(left_high, right_high) * 0.98:  # è‡³å°‘ä½2%
                return None
            
            # 6. éªŒè¯çªç ´ç¡®è®¤ï¼ˆå½“å‰ä»·æ ¼è·Œç ´é¢ˆçº¿ï¼‰
            current_price = closes[-1]
            neckline = middle_valley
            
            if current_price >= neckline:
                return None  # è¿˜æœªè·Œç ´ï¼Œä¸äº§ç”Ÿä¿¡å·
            
            # 7. æˆäº¤é‡ç¡®è®¤
            recent_volume = np.mean(volumes[-5:])
            base_volume = np.mean(volumes[left_peak_idx:right_peak_idx+1])
            volume_ratio = recent_volume / base_volume if base_volume > 0 else 1.0
            
            # 8. RSIç¡®è®¤ï¼ˆä½¿ç”¨å®‰å…¨è®¡ç®—ï¼‰
            rsi_values = self._safe_rsi_calculation(closes)
            current_rsi = rsi_values[-1]
            
            # 9. è®¡ç®—ç½®ä¿¡åº¦ï¼ˆé•œåƒé€»è¾‘ï¼‰
            confidence_factors = {
                'similarity': max(0, 1 - similarity / self.similarity_thresh) * 0.25,
                'volume': min(volume_ratio / self.volume_mult, 1.0) * 0.25,
                'rsi': (1.0 if current_rsi > self.rsi_bear_thresh else 0.5) * 0.25,
                'breakout': min((neckline - current_price) / neckline / 0.02, 1.0) * 0.25
            }
            
            total_confidence = sum(confidence_factors.values())
            
            # 10. ç½®ä¿¡åº¦æ£€æŸ¥
            if total_confidence < self.min_confidence:
                return None
            
            # 11. è®¡ç®—äº¤æ˜“å‚æ•°
            entry_price = current_price
            height = min(left_high, right_high) - neckline  # å½¢æ€é«˜åº¦
            target_price = neckline - height                # ç›®æ ‡ä»·æ ¼ï¼ˆåšç©ºï¼‰
            stop_loss = max(left_high, right_high) * 1.02   # æ­¢æŸè®¾åœ¨æœ€é«˜ç‚¹ä¸Šæ–¹2%
            
            # 12. åˆ›å»ºä¿¡å·
            signal = PatternSignal(
                type=DoublePatternType.DOUBLE_TOP_BEAR,
                confidence=total_confidence,
                entry_price=entry_price,
                target_price=target_price,
                stop_loss=stop_loss,
                formation_bars=formation_bars,
                volume_ratio=volume_ratio,
                similarity_score=1 - similarity,
                rsi_confirmation=current_rsi,
                metadata={
                    'left_peak_idx': int(left_peak_idx),
                    'right_peak_idx': int(right_peak_idx),
                    'middle_valley_idx': int(middle_valley_idx),
                    'neckline': float(neckline),
                    'confidence_breakdown': confidence_factors
                }
            )
            
            self.logger.info(f"âœ… æ£€æµ‹åˆ°åŒé¡¶å½¢æ€: ç½®ä¿¡åº¦={total_confidence:.2f}, "
                           f"å½¢æ€å‘¨æœŸ={formation_bars}, ç›¸ä¼¼åº¦={1-similarity:.2f}")
            
            return signal
            
        except Exception as e:
            self.logger.error(f"âŒ åŒé¡¶æ£€æµ‹å¼‚å¸¸: {e}")
            return None

    def detect_patterns(
        self, 
        highs: np.ndarray, 
        lows: np.ndarray, 
        closes: np.ndarray, 
        volumes: np.ndarray
    ) -> List[PatternSignal]:
        """
        ğŸ” æ£€æµ‹æ‰€æœ‰åŒé‡å½¢æ€
        
        Returns:
            List[PatternSignal]: æ£€æµ‹åˆ°çš„å½¢æ€ä¿¡å·åˆ—è¡¨
        """
        patterns = []
        
        try:
            # æ£€æµ‹Wåº•å½¢æ€
            double_bottom = self.detect_double_bottom(highs, lows, closes, volumes)
            if double_bottom:
                patterns.append(double_bottom)
            
            # æ£€æµ‹åŒé¡¶å½¢æ€  
            double_top = self.detect_double_top(highs, lows, closes, volumes)
            if double_top:
                patterns.append(double_top)
            
            if patterns:
                self.logger.info(f"ğŸ¯ åŒé‡å½¢æ€æ£€æµ‹å®Œæˆ: å‘ç° {len(patterns)} ä¸ªæœ‰æ•ˆå½¢æ€")
            else:
                self.logger.debug("ğŸ” åŒé‡å½¢æ€æ£€æµ‹å®Œæˆ: æœªå‘ç°æœ‰æ•ˆå½¢æ€")
                
        except Exception as e:
            self.logger.error(f"âŒ åŒé‡å½¢æ€æ£€æµ‹å¼‚å¸¸: {e}")
        
        return patterns

    def get_pattern_summary(self, patterns: List[PatternSignal]) -> Dict[str, Any]:
        """
        ğŸ“Š è·å–å½¢æ€æ£€æµ‹æ‘˜è¦ç»Ÿè®¡
        """
        if not patterns:
            return {
                'total_patterns': 0,
                'pattern_types': {},
                'avg_confidence': 0.0,
                'max_confidence': 0.0
            }
        
        pattern_types = {}
        confidences = []
        
        for pattern in patterns:
            pattern_type = pattern.type.value
            pattern_types[pattern_type] = pattern_types.get(pattern_type, 0) + 1
            confidences.append(pattern.confidence)
        
        return {
            'total_patterns': len(patterns),
            'pattern_types': pattern_types,
            'avg_confidence': np.mean(confidences),
            'max_confidence': np.max(confidences)
        } 