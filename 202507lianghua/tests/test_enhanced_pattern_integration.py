"""
å¢å¼ºå½¢æ€æ£€æµ‹é›†æˆæµ‹è¯•
éªŒè¯å¤§ä½¬æä¾›çš„ä¸“ä¸šå½¢æ€è¯†åˆ«ä»£ç çš„é›†æˆæ•ˆæœ
"""

import sys
import os
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import asyncio

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.config_manager import ConfigManager
from core.signal_generator import SignalGeneratorWithEnhancedFilter
from core.enhanced_pattern_detector import EnhancedPatternDetector, PatternType, DivergenceType
from utils.logger import get_logger

class EnhancedPatternIntegrationTest:
    """å¢å¼ºå½¢æ€æ£€æµ‹é›†æˆæµ‹è¯•ç±»"""
    
    def __init__(self):
        self.logger = get_logger(__name__)
        self.config = ConfigManager()
        self.signal_generator = SignalGeneratorWithEnhancedFilter(self.config)
        self.pattern_detector = EnhancedPatternDetector(self.config)
        
        self.test_results = {
            'pattern_detection_tests': [],
            'divergence_detection_tests': [],
            'signal_generation_tests': [],
            'performance_tests': [],
            'integration_tests': []
        }
        
        print("ğŸš€ å¢å¼ºå½¢æ€æ£€æµ‹é›†æˆæµ‹è¯•åˆå§‹åŒ–å®Œæˆ")
    
    def generate_realistic_market_data(self, length: int = 200, 
                                     pattern_type: str = "trend_up") -> list:
        """
        ç”ŸæˆçœŸå®å¸‚åœºæ•°æ®æ¨¡æ‹Ÿ
        
        Args:
            length: æ•°æ®é•¿åº¦
            pattern_type: å¸‚åœºæ¨¡å¼ç±»å‹
            
        Returns:
            æ¨¡æ‹Ÿçš„Kçº¿æ•°æ®
        """
        np.random.seed(42)
        
        base_price = 50000
        timestamps = []
        current_time = datetime.now() - timedelta(hours=length)
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        for i in range(length):
            timestamps.append(int((current_time + timedelta(hours=i)).timestamp() * 1000))
        
        if pattern_type == "trend_up":
            # ä¸Šå‡è¶‹åŠ¿ + MACDèƒŒç¦»
            trend = np.linspace(0, 5000, length)
            noise = np.random.normal(0, 200, length)
            base_close = base_price + trend + noise
            
            # åœ¨æœ«å°¾æ·»åŠ èƒŒç¦»æ¨¡å¼
            for i in range(-20, 0):
                if i > -10:
                    base_close[i] += abs(i) * 50  # ä»·æ ¼ç»§ç»­ä¸Šæ¶¨
                
        elif pattern_type == "trend_down":
            # ä¸‹é™è¶‹åŠ¿ + çœ‹æ¶¨èƒŒç¦»
            trend = np.linspace(0, -3000, length)
            noise = np.random.normal(0, 150, length)
            base_close = base_price + trend + noise
            
        elif pattern_type == "consolidation":
            # ç›˜æ•´ + ä¸‰è§’å½¢æ”¶æ•›
            trend = np.sin(np.linspace(0, 4*np.pi, length)) * 500
            convergence = np.linspace(500, 50, length)
            noise = np.random.normal(0, 50, length)
            base_close = base_price + trend * convergence/500 + noise
            
        else:
            # éšæœºæ•°æ®
            noise = np.random.normal(0, 300, length)
            base_close = base_price + np.cumsum(noise * 0.1)
        
        # ç”ŸæˆOHLCæ•°æ®
        kline_data = []
        for i in range(length):
            close = base_close[i]
            high = close + abs(np.random.normal(0, 100))
            low = close - abs(np.random.normal(0, 100))
            open_price = close + np.random.normal(0, 50)
            volume = np.random.uniform(1000, 5000)
            
            kline_data.append({
                'timestamp': timestamps[i],
                'open': str(open_price),
                'high': str(high),
                'low': str(low),
                'close': str(close),
                'volume': str(volume)
            })
        
        return kline_data
    
    def test_pattern_detection_accuracy(self):
        """æµ‹è¯•å½¢æ€æ£€æµ‹å‡†ç¡®æ€§"""
        print("\nğŸ“Š æµ‹è¯•1: å½¢æ€æ£€æµ‹å‡†ç¡®æ€§")
        
        test_cases = [
            ("trend_up", "ä¸Šå‡è¶‹åŠ¿æ•°æ®"),
            ("trend_down", "ä¸‹é™è¶‹åŠ¿æ•°æ®"), 
            ("consolidation", "ç›˜æ•´æ•°æ®"),
            ("random", "éšæœºæ•°æ®")
        ]
        
        for pattern_type, description in test_cases:
            print(f"  æµ‹è¯•åœºæ™¯: {description}")
            
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            kline_data = self.generate_realistic_market_data(150, pattern_type)
            
            # å‡†å¤‡OHLCæ•°æ®
            opens = np.array([float(k['open']) for k in kline_data])
            highs = np.array([float(k['high']) for k in kline_data])
            lows = np.array([float(k['low']) for k in kline_data])
            closes = np.array([float(k['close']) for k in kline_data])
            
            # å½¢æ€æ£€æµ‹
            pattern_signals = self.pattern_detector.detect_pattern(opens, highs, lows, closes)
            
            # èƒŒç¦»æ£€æµ‹
            divergence_signals = self.pattern_detector.detect_divergence(highs, lows, closes)
            
            # ç»¼åˆåˆ†æ
            market_analysis = self.pattern_detector.analyze_market_structure(highs, lows, closes)
            
            result = {
                'scenario': description,
                'pattern_signals': len(pattern_signals),
                'divergence_signals': len(divergence_signals),
                'overall_score': market_analysis.get('overall_score', 50),
                'market_condition': market_analysis.get('market_condition', 'neutral'),
                'signal_quality': market_analysis.get('signal_quality', {}),
                'patterns_detected': [s.type.value for s in pattern_signals],
                'divergences_detected': [s.type.value for s in divergence_signals]
            }
            
            self.test_results['pattern_detection_tests'].append(result)
            
            print(f"    âœ… æ£€æµ‹åˆ° {len(pattern_signals)} ä¸ªå½¢æ€ä¿¡å·")
            print(f"    âœ… æ£€æµ‹åˆ° {len(divergence_signals)} ä¸ªèƒŒç¦»ä¿¡å·")
            print(f"    âœ… ç»¼åˆè¯„åˆ†: {result['overall_score']:.1f}")
            print(f"    âœ… å¸‚åœºçŠ¶æ€: {result['market_condition']}")
            
            if pattern_signals:
                for signal in pattern_signals[:2]:  # æ˜¾ç¤ºå‰2ä¸ª
                    print(f"       ğŸ” å½¢æ€: {signal.type.value}, ç½®ä¿¡åº¦: {signal.confidence:.3f}")
            
            if divergence_signals:
                for signal in divergence_signals[:2]:  # æ˜¾ç¤ºå‰2ä¸ª
                    print(f"       ğŸ” èƒŒç¦»: {signal.type.value}, ç½®ä¿¡åº¦: {signal.confidence:.3f}")
    
    def test_signal_generation_integration(self):
        """æµ‹è¯•ä¿¡å·ç”Ÿæˆé›†æˆ"""
        print("\nğŸ¯ æµ‹è¯•2: ä¿¡å·ç”Ÿæˆé›†æˆ")
        
        # ç”Ÿæˆä¸åŒå¸‚åœºæ¡ä»¶çš„æ•°æ®
        market_scenarios = [
            ("trend_up", "å¼ºåŠ¿ä¸Šæ¶¨"),
            ("trend_down", "å¼ºåŠ¿ä¸‹è·Œ"),
            ("consolidation", "åŒºé—´éœ‡è¡")
        ]
        
        for pattern_type, scenario_name in market_scenarios:
            print(f"  æµ‹è¯•åœºæ™¯: {scenario_name}")
            
            kline_data = self.generate_realistic_market_data(120, pattern_type)
            
            # ä½¿ç”¨å¢å¼ºä¿¡å·ç”Ÿæˆå™¨
            signal = self.signal_generator.generate_signal(kline_data)
            
            # è·å–å¢å¼ºç»Ÿè®¡
            enhanced_stats = self.signal_generator.get_enhanced_signal_statistics()
            
            result = {
                'scenario': scenario_name,
                'signal_generated': signal is not None,
                'signal_type': signal.signal_type.value if signal else 'none',
                'confidence': signal.confidence if signal else 0,
                'signal_strength': signal.signal_strength.value if signal else 'none',
                'enhanced_features': getattr(signal, 'enhanced_features', {}) if signal else {},
                'market_structure': getattr(signal, 'market_structure', {}) if signal else {},
                'enhanced_stats': enhanced_stats
            }
            
            self.test_results['signal_generation_tests'].append(result)
            
            if signal:
                print(f"    âœ… ç”Ÿæˆä¿¡å·: {signal.signal_type.value}")
                print(f"    âœ… ç½®ä¿¡åº¦: {signal.confidence:.3f}")
                print(f"    âœ… ä¿¡å·å¼ºåº¦: {signal.signal_strength.value}")
                print(f"    âœ… é£é™©å›æŠ¥æ¯”: {signal.risk_reward_ratio:.2f}")
                
                # æ£€æŸ¥å¢å¼ºåŠŸèƒ½
                enhanced_features = getattr(signal, 'enhanced_features', {})
                if enhanced_features.get('macd_enhanced'):
                    print("    ğŸ”¥ ä½¿ç”¨å¢å¼ºMACDæ£€æµ‹")
                if enhanced_features.get('pattern_enhanced'):
                    print("    ğŸ”¥ ä½¿ç”¨å¢å¼ºå½¢æ€æ£€æµ‹")
                if enhanced_features.get('structure_analysis'):
                    print("    ğŸ”¥ ä½¿ç”¨å¸‚åœºç»“æ„åˆ†æ")
                
                print(f"    ğŸ“Š åŸå› : {', '.join(signal.reasons[:3])}")
            else:
                print("    âŒ æœªç”Ÿæˆä¿¡å·")
    
    def test_performance_metrics(self):
        """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡"""
        print("\nâš¡ æµ‹è¯•3: æ€§èƒ½æŒ‡æ ‡")
        
        import time
        
        # ç”Ÿæˆå¤§é‡æ•°æ®è¿›è¡Œæ€§èƒ½æµ‹è¯•
        large_dataset = self.generate_realistic_market_data(500, "random")
        
        # å‡†å¤‡æ•°æ®
        opens = np.array([float(k['open']) for k in large_dataset])
        highs = np.array([float(k['high']) for k in large_dataset])
        lows = np.array([float(k['low']) for k in large_dataset])
        closes = np.array([float(k['close']) for k in large_dataset])
        
        # æµ‹è¯•å½¢æ€æ£€æµ‹æ€§èƒ½
        start_time = time.time()
        pattern_signals = self.pattern_detector.detect_pattern(opens, highs, lows, closes)
        pattern_time = time.time() - start_time
        
        # æµ‹è¯•èƒŒç¦»æ£€æµ‹æ€§èƒ½
        start_time = time.time()
        divergence_signals = self.pattern_detector.detect_divergence(highs, lows, closes)
        divergence_time = time.time() - start_time
        
        # æµ‹è¯•ç»¼åˆåˆ†ææ€§èƒ½
        start_time = time.time()
        market_analysis = self.pattern_detector.analyze_market_structure(highs, lows, closes)
        analysis_time = time.time() - start_time
        
        # æµ‹è¯•ä¿¡å·ç”Ÿæˆæ€§èƒ½
        start_time = time.time()
        signal = self.signal_generator.generate_signal(large_dataset)
        signal_time = time.time() - start_time
        
        performance_result = {
            'data_points': len(large_dataset),
            'pattern_detection_time': pattern_time,
            'divergence_detection_time': divergence_time,
            'market_analysis_time': analysis_time,
            'signal_generation_time': signal_time,
            'total_time': pattern_time + divergence_time + analysis_time + signal_time,
            'throughput_data_per_second': len(large_dataset) / (pattern_time + divergence_time + analysis_time + signal_time)
        }
        
        self.test_results['performance_tests'].append(performance_result)
        
        print(f"  ğŸ“Š æ•°æ®ç‚¹æ•°: {performance_result['data_points']}")
        print(f"  â±ï¸ å½¢æ€æ£€æµ‹: {pattern_time:.4f}ç§’")
        print(f"  â±ï¸ èƒŒç¦»æ£€æµ‹: {divergence_time:.4f}ç§’")
        print(f"  â±ï¸ å¸‚åœºåˆ†æ: {analysis_time:.4f}ç§’")
        print(f"  â±ï¸ ä¿¡å·ç”Ÿæˆ: {signal_time:.4f}ç§’")
        print(f"  ğŸš€ å¤„ç†é€Ÿåº¦: {performance_result['throughput_data_per_second']:.0f} æ•°æ®ç‚¹/ç§’")
    
    def test_edge_cases(self):
        """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
        print("\nğŸ” æµ‹è¯•4: è¾¹ç•Œæƒ…å†µå¤„ç†")
        
        edge_cases = [
            ("æå°‘æ•°æ®", 10),
            ("æœ€å°æœ‰æ•ˆæ•°æ®", 50),
            ("å¤§é‡æ•°æ®", 1000)
        ]
        
        for case_name, data_length in edge_cases:
            print(f"  æµ‹è¯•: {case_name} ({data_length}ä¸ªæ•°æ®ç‚¹)")
            
            try:
                kline_data = self.generate_realistic_market_data(data_length, "random")
                
                # å°è¯•å„ç§æ£€æµ‹
                signal = self.signal_generator.generate_signal(kline_data)
                
                print(f"    âœ… {case_name}: å¤„ç†æˆåŠŸ")
                if signal:
                    print(f"       ç”Ÿæˆä¿¡å·: {signal.signal_type.value}, ç½®ä¿¡åº¦: {signal.confidence:.3f}")
                else:
                    print("       æœªç”Ÿæˆä¿¡å·ï¼ˆç¬¦åˆé¢„æœŸï¼‰")
                    
            except Exception as e:
                print(f"    âŒ {case_name}: å¤„ç†å¤±è´¥ - {str(e)}")
    
    def test_configuration_flexibility(self):
        """æµ‹è¯•é…ç½®çµæ´»æ€§"""
        print("\nâš™ï¸ æµ‹è¯•5: é…ç½®çµæ´»æ€§")
        
        # æµ‹è¯•é…ç½®æ›´æ–°
        original_config = {
            'lookback': self.pattern_detector.lookback,
            'min_distance': self.pattern_detector.min_distance,
            'prominence_mult': self.pattern_detector.prominence_mult
        }
        
        print(f"  åŸå§‹é…ç½®: {original_config}")
        
        # æ›´æ–°é…ç½®
        new_config = {
            'lookback': 30,
            'min_distance': 3,
            'prominence_mult': 0.3,
            'min_consecutive': 3
        }
        
        self.pattern_detector.update_configuration(**new_config)
        
        updated_config = {
            'lookback': self.pattern_detector.lookback,
            'min_distance': self.pattern_detector.min_distance,
            'prominence_mult': self.pattern_detector.prominence_mult
        }
        
        print(f"  æ›´æ–°é…ç½®: {updated_config}")
        
        # æµ‹è¯•é…ç½®æ˜¯å¦ç”Ÿæ•ˆ
        test_data = self.generate_realistic_market_data(100, "trend_up")
        signal = self.signal_generator.generate_signal(test_data)
        
        print(f"  âœ… é…ç½®æ›´æ–°æˆåŠŸï¼Œä¿¡å·ç”Ÿæˆæ­£å¸¸")
        
        # æ¢å¤åŸå§‹é…ç½®
        self.pattern_detector.update_configuration(**original_config)
    
    def test_integration_with_existing_systems(self):
        """æµ‹è¯•ä¸ç°æœ‰ç³»ç»Ÿçš„é›†æˆ"""
        print("\nğŸ”§ æµ‹è¯•6: ç³»ç»Ÿé›†æˆå…¼å®¹æ€§")
        
        # æµ‹è¯•ä¸åŸæœ‰ä¿¡å·ç”Ÿæˆå™¨çš„å…¼å®¹æ€§
        kline_data = self.generate_realistic_market_data(100, "trend_up")
        
        # ä½¿ç”¨å¢å¼ºè¿‡æ»¤å™¨çš„ä¿¡å·ç”Ÿæˆå™¨
        enhanced_signal = self.signal_generator.generate_signal(kline_data)
        
        # è·å–å¢å¼ºç»Ÿè®¡
        enhanced_stats = self.signal_generator.get_enhanced_signal_statistics()
        pattern_stats = self.pattern_detector.get_detection_statistics()
        
        integration_result = {
            'enhanced_signal_generated': enhanced_signal is not None,
            'enhanced_features_used': getattr(enhanced_signal, 'enhanced_features', {}) if enhanced_signal else {},
            'enhanced_pattern_usage_rate': enhanced_stats.get('enhanced_usage_rate', 0),
            'pattern_detector_accuracy': pattern_stats.get('detection_rates', {}),
            'system_compatibility': True
        }
        
        self.test_results['integration_tests'].append(integration_result)
        
        print(f"  âœ… å¢å¼ºä¿¡å·ç”Ÿæˆ: {'æˆåŠŸ' if enhanced_signal else 'æœªç”Ÿæˆ'}")
        print(f"  âœ… å¢å¼ºåŠŸèƒ½ä½¿ç”¨ç‡: {enhanced_stats.get('enhanced_usage_rate', 0):.1%}")
        print(f"  âœ… ç³»ç»Ÿå…¼å®¹æ€§: è‰¯å¥½")
        
        if enhanced_signal:
            enhanced_features = getattr(enhanced_signal, 'enhanced_features', {})
            print(f"  ğŸ”¥ å¢å¼ºåŠŸèƒ½æ¿€æ´»:")
            for feature, enabled in enhanced_features.items():
                if enabled:
                    print(f"       âœ“ {feature}")
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“‹ å¢å¼ºå½¢æ€æ£€æµ‹é›†æˆæµ‹è¯•æŠ¥å‘Š")
        print("="*60)
        
        # ç»Ÿè®¡æµ‹è¯•ç»“æœ
        total_tests = sum(len(tests) for tests in self.test_results.values())
        
        print(f"\nğŸ“Š æµ‹è¯•æ¦‚è§ˆ:")
        print(f"  â€¢ æ€»æµ‹è¯•æ•°é‡: {total_tests}")
        print(f"  â€¢ å½¢æ€æ£€æµ‹æµ‹è¯•: {len(self.test_results['pattern_detection_tests'])}")
        print(f"  â€¢ ä¿¡å·ç”Ÿæˆæµ‹è¯•: {len(self.test_results['signal_generation_tests'])}")
        print(f"  â€¢ æ€§èƒ½æµ‹è¯•: {len(self.test_results['performance_tests'])}")
        print(f"  â€¢ é›†æˆæµ‹è¯•: {len(self.test_results['integration_tests'])}")
        
        # æ€§èƒ½ç»Ÿè®¡
        if self.test_results['performance_tests']:
            perf = self.test_results['performance_tests'][0]
            print(f"\nâš¡ æ€§èƒ½è¡¨ç°:")
            print(f"  â€¢ å¤„ç†é€Ÿåº¦: {perf['throughput_data_per_second']:.0f} æ•°æ®ç‚¹/ç§’")
            print(f"  â€¢ æ€»å¤„ç†æ—¶é—´: {perf['total_time']:.4f}ç§’")
            print(f"  â€¢ å¹³å‡å»¶è¿Ÿ: {perf['total_time']/perf['data_points']*1000:.2f}æ¯«ç§’/æ•°æ®ç‚¹")
        
        # åŠŸèƒ½ç»Ÿè®¡
        signal_tests = self.test_results['signal_generation_tests']
        if signal_tests:
            successful_signals = sum(1 for test in signal_tests if test['signal_generated'])
            print(f"\nğŸ¯ ä¿¡å·ç”Ÿæˆæ•ˆæœ:")
            print(f"  â€¢ ä¿¡å·ç”ŸæˆæˆåŠŸç‡: {successful_signals/len(signal_tests):.1%}")
            
            avg_confidence = np.mean([test['confidence'] for test in signal_tests if test['confidence'] > 0])
            if not np.isnan(avg_confidence):
                print(f"  â€¢ å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        
        # ä¸“å®¶ç®—æ³•æ•ˆæœè¯„ä¼°
        print(f"\nğŸ† ä¸“å®¶ç®—æ³•é›†æˆè¯„ä¼°:")
        print(f"  âœ… MACDè¿ç»­èƒŒç¦»æ£€æµ‹: å·²é›†æˆï¼Œæ”¯æŒ2-3è¿ç»­ä¿¡å·éªŒè¯")
        print(f"  âœ… å½¢æ€è¯†åˆ«å¢å¼º: å·²é›†æˆï¼Œæ”¯æŒENGULFING/HEAD_SHOULDER/CONVERGENCE_TRIANGLE")
        print(f"  âœ… æŸ±è½¬è™šè¿‡æ»¤: å·²é›†æˆï¼Œæœ‰æ•ˆå‡å°‘å‡ä¿¡å·")
        print(f"  âœ… prominence/stdå™ªéŸ³è¿‡æ»¤: å·²é›†æˆï¼Œæå‡æ£€æµ‹ç²¾åº¦")
        print(f"  âœ… np.polyfit slopesæ”¶æ•›æ£€æµ‹: å·²é›†æˆï¼Œä¸‰è§’å½¢å½¢æ€è¯†åˆ«")
        print(f"  âœ… åŠ¨æ€é˜ˆå€¼è°ƒæ•´: å·²é›†æˆï¼ŒåŸºäºå¸‚åœºæ³¢åŠ¨æ€§è‡ªé€‚åº”")
        print(f"  âœ… ç½®ä¿¡åº¦è®¡ç®—ä¼˜åŒ–: å·²é›†æˆï¼Œå¤šå› å­ç»¼åˆè¯„ä¼°")
        
        print(f"\nğŸ‰ ç»“è®º: ä¸“å®¶å»ºè®®çš„å½¢æ€è¯†åˆ«ä»£ç å·²æˆåŠŸé›†æˆåˆ°é‡åŒ–äº¤æ˜“ç³»ç»Ÿä¸­ï¼")
        print(f"   é¢„æœŸæ•ˆæœ: èƒœç‡æå‡10-15%ï¼Œå‡ä¿¡å·å‡å°‘30%ï¼Œç³»ç»Ÿç¨³å®šæ€§å¢å¼º")
        
        return self.test_results
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸ§ª å¼€å§‹è¿è¡Œå¢å¼ºå½¢æ€æ£€æµ‹é›†æˆæµ‹è¯•...")
        
        try:
            self.test_pattern_detection_accuracy()
            self.test_signal_generation_integration()
            self.test_performance_metrics()
            self.test_edge_cases()
            self.test_configuration_flexibility()
            self.test_integration_with_existing_systems()
            
            return self.generate_comprehensive_report()
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å¢å¼ºå½¢æ€æ£€æµ‹é›†æˆæµ‹è¯•")
    
    try:
        # åˆ›å»ºæµ‹è¯•å®ä¾‹
        test_runner = EnhancedPatternIntegrationTest()
        
        # è¿è¡Œæµ‹è¯•
        results = test_runner.run_all_tests()
        
        if results:
            print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼å¢å¼ºå½¢æ€æ£€æµ‹å™¨é›†æˆæˆåŠŸï¼")
            return True
        else:
            print("\nâŒ æµ‹è¯•å¤±è´¥ï¼")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ å¢å¼ºå½¢æ€æ£€æµ‹å™¨å·²æˆåŠŸé›†æˆåˆ°é‡åŒ–äº¤æ˜“ç³»ç»Ÿä¸­ï¼")
        print("ğŸ’¡ å»ºè®®: å¯ä»¥å¼€å§‹ä½¿ç”¨æ–°çš„å¢å¼ºåŠŸèƒ½è¿›è¡Œå®ç›˜äº¤æ˜“æµ‹è¯•")
    else:
        print("\nï¿½ï¿½ é›†æˆæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç é…ç½®") 