"""
çœŸå®å¸‚åœºæ•°æ®æµ‹è¯• - éªŒè¯å¤§ä½¬ç®—æ³•æ•ˆæœ
ä½¿ç”¨æ›´æ¥è¿‘çœŸå®å¸‚åœºçš„æ•°æ®æ¨¡æ‹Ÿ
"""

import numpy as np
import talib as ta
from scipy.signal import find_peaks
from typing import List, Tuple, Optional
from dataclasses import dataclass

@dataclass
class DivergenceSignal:
    type: str  # 'bearish' / 'bullish'
    strength: float
    confidence: float
    indices: List[int]

@dataclass
class PatternSignal:
    type: str
    confidence: float
    details: dict

class MACDMorphDetector:
    """å¤§ä½¬çš„ä¸“ä¸šå½¢æ€æ£€æµ‹å™¨"""
    def __init__(self, macd_fast: int = 13, macd_slow: int = 34, macd_signal: int = 9,
                 lookback: int = 50, min_distance: int = 5, prominence_mult: float = 0.5,
                 min_gap: float = 0.1, min_consecutive: int = 2, tolerance: int = 2,
                 vol_factor_mult: float = 0.05, 
                 morph_patterns: List[str] = ["ENGULFING", "HEAD_SHOULDER", "CONVERGENCE_TRIANGLE"]):
        self.macd_fast = macd_fast
        self.macd_slow = macd_slow
        self.macd_signal = macd_signal
        self.lookback = lookback
        self.min_distance = min_distance
        self.prominence_mult = prominence_mult
        self.min_gap = min_gap
        self.min_consecutive = min_consecutive
        self.tolerance = tolerance
        self.vol_factor_mult = vol_factor_mult
        self.morph_patterns = morph_patterns

    def compute_macd(self, closes: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """è®¡ç®—MACD"""
        return ta.MACD(closes, fastperiod=self.macd_fast, slowperiod=self.macd_slow, signalperiod=self.macd_signal)

    def detect_divergence(self, highs: np.ndarray, lows: np.ndarray, closes: np.ndarray, vol_factor: float = 0.0) -> List[DivergenceSignal]:
        """èƒŒç¦»æ£€æµ‹"""
        if len(closes) < self.lookback:
            return []

        macd, signal, hist = self.compute_macd(closes[-self.lookback:])
        
        # è¿‡æ»¤NaN
        valid_mask = ~np.isnan(hist)
        if not np.any(valid_mask):
            return []
        
        hist = hist[valid_mask]
        valid_length = len(hist)
        
        # è°ƒæ•´å¯¹åº”çš„ä»·æ ¼æ•°æ®
        price_start = len(highs) - valid_length
        adjusted_highs = highs[price_start:]
        adjusted_lows = lows[price_start:]

        gap_thresh = self.min_gap + vol_factor * self.vol_factor_mult

        # è®¡ç®—prominenceï¼ˆé™ä½é˜ˆå€¼ä»¥ä¾¿æ£€æµ‹åˆ°ä¿¡å·ï¼‰
        price_prominence = max(self.prominence_mult * np.std(adjusted_highs), np.std(adjusted_highs) * 0.1)
        macd_prominence = max(self.prominence_mult * np.std(hist), np.std(hist) * 0.1)

        # æ£€æµ‹å³°è°·
        price_peaks, _ = find_peaks(adjusted_highs, distance=self.min_distance, prominence=price_prominence)
        price_valleys, _ = find_peaks(-adjusted_lows, distance=self.min_distance, prominence=price_prominence)
        macd_peaks, _ = find_peaks(hist, distance=self.min_distance, prominence=macd_prominence)
        macd_valleys, _ = find_peaks(-hist, distance=self.min_distance, prominence=macd_prominence)

        signals = []
        
        # çœ‹è·ŒèƒŒç¦»
        bear_signals = self._find_consecutive_divergence(price_peaks, macd_peaks, adjusted_highs, hist, True, gap_thresh)
        signals.extend(bear_signals)
        
        # çœ‹æ¶¨èƒŒç¦»
        bull_signals = self._find_consecutive_divergence(price_valleys, macd_valleys, -adjusted_lows, -hist, False, gap_thresh)
        signals.extend(bull_signals)

        return signals

    def _find_consecutive_divergence(self, price_extrema: np.ndarray, macd_extrema: np.ndarray, 
                                      prices: np.ndarray, macd: np.ndarray, is_bearish: bool, gap_thresh: float) -> List[DivergenceSignal]:
        signals = []
        if len(price_extrema) < self.min_consecutive or len(macd_extrema) < self.min_consecutive:
            return signals

        price_extrema = np.sort(price_extrema)
        macd_extrema = np.sort(macd_extrema)

        for start in range(len(price_extrema) - self.min_consecutive + 1):
            seq_price = price_extrema[start:start + self.min_consecutive]
            seq_macd = [self._find_closest(macd_extrema, idx) for idx in seq_price]
            if any(m is None for m in seq_macd):
                continue

            # æ£€æŸ¥æŸ±è½¬è™š
            turn_virtual = macd[seq_macd[-1]] < 0 if not is_bearish else macd[seq_macd[-1]] > 0
            if not turn_virtual:
                continue

            div_count = 0
            total_strength = 0
            for i in range(1, self.min_consecutive):
                price_diff = prices[seq_price[i]] - prices[seq_price[i-1]]
                macd_diff = macd[seq_macd[i]] - macd[seq_macd[i-1]]
                
                is_divergence = (is_bearish and price_diff > 0 and macd_diff < 0) or (not is_bearish and price_diff < 0 and macd_diff > 0)
                if is_divergence:
                    strength = abs(macd_diff / price_diff) if abs(price_diff) > 1e-8 else 0
                    if strength > gap_thresh:
                        div_count += 1
                        total_strength += strength

            if div_count >= self.min_consecutive - 1:
                avg_strength = total_strength / div_count if div_count > 0 else 0
                confidence = min((avg_strength / gap_thresh) * 0.5 + 0.5, 1.0)
                signal_type = 'bearish' if is_bearish else 'bullish'
                signals.append(DivergenceSignal(signal_type, avg_strength, confidence, seq_price.tolist()))

        return signals

    def _find_closest(self, extrema: np.ndarray, target_idx: int) -> Optional[int]:
        if len(extrema) == 0:
            return None
        distances = np.abs(extrema - target_idx)
        min_dist_idx = np.argmin(distances)
        if distances[min_dist_idx] <= self.tolerance:
            return extrema[min_dist_idx]
        return None

    def detect_pattern(self, opens: np.ndarray, highs: np.ndarray, lows: np.ndarray, closes: np.ndarray) -> List[PatternSignal]:
        """å½¢æ€æ£€æµ‹"""
        signals = []
        if len(closes) < self.lookback:
            return signals
            
        lookback_data = min(self.lookback, len(closes))
        
        opens_slice = opens[-lookback_data:]
        highs_slice = highs[-lookback_data:]
        lows_slice = lows[-lookback_data:]
        closes_slice = closes[-lookback_data:]

        # ENGULFINGæ£€æµ‹
        if "ENGULFING" in self.morph_patterns:
            try:
                engulfing = ta.CDLENGULFING(opens_slice, highs_slice, lows_slice, closes_slice)
                recent_engulfing = engulfing[-5:]  # æ£€æŸ¥æœ€è¿‘5æ ¹Kçº¿
                
                for i, val in enumerate(recent_engulfing):
                    if val != 0:
                        conf = 0.8 if val > 0 else 0.7
                        pattern_type = 'ENGULFING_BULL' if val > 0 else 'ENGULFING_BEAR'
                        signals.append(PatternSignal(pattern_type, conf, {'candle_index': len(closes_slice)-5+i, 'strength': abs(val)}))
            except:
                pass

        # HEAD_SHOULDERæ£€æµ‹
        if "HEAD_SHOULDER" in self.morph_patterns:
            try:
                # é™ä½prominenceè¦æ±‚
                prominence_threshold = max(self.prominence_mult * np.std(highs_slice), np.std(highs_slice) * 0.05)
                peaks_idx = find_peaks(highs_slice, distance=max(self.min_distance//2, 2), prominence=prominence_threshold)[0]
                
                if len(peaks_idx) >= 3:
                    # æ£€æŸ¥å¤šä¸ªå¤´è‚©ç»„åˆ
                    for i in range(len(peaks_idx) - 2):
                        left, head, right = peaks_idx[i], peaks_idx[i+1], peaks_idx[i+2]
                        
                        if (highs_slice[head] > highs_slice[left] and 
                            highs_slice[head] > highs_slice[right]):
                            
                            shoulder_diff = abs(highs_slice[left] - highs_slice[right])
                            shoulder_threshold = np.std(highs_slice) * 0.5  # æ”¾å®½æ¡ä»¶
                            
                            if shoulder_diff < shoulder_threshold:
                                # ç®€åŒ–é¢ˆçº¿æ£€æŸ¥
                                left_range = max(0, left-3)
                                right_range = min(len(lows_slice), right+3)
                                neckline = np.mean([np.min(lows_slice[left_range:head]), 
                                                  np.min(lows_slice[head:right_range])])
                                
                                # æ£€æŸ¥æœ€è¿‘ä»·æ ¼æ˜¯å¦æ¥è¿‘çªç ´
                                recent_lows = lows_slice[-5:]
                                if np.min(recent_lows) < neckline * 1.02:  # 2%å®¹å¿åº¦
                                    conf = max(0.6, 0.85 - shoulder_diff / highs_slice[head])
                                    signals.append(PatternSignal('HEAD_SHOULDER_BEAR', conf, 
                                                                {'neckline': neckline, 'peaks': [left, head, right]}))
            except:
                pass

        # CONVERGENCE_TRIANGLEæ£€æµ‹
        if "CONVERGENCE_TRIANGLE" in self.morph_patterns:
            try:
                x = np.arange(len(highs_slice))
                if len(x) >= 10:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
                    high_slope, high_inter = np.polyfit(x, highs_slice, 1)
                    low_slope, low_inter = np.polyfit(x, lows_slice, 1)
                    
                    # æ”¾å®½æ”¶æ•›æ¡ä»¶
                    if abs(high_slope) > 0.1 and abs(low_slope) > 0.1:  # ç¡®ä¿æœ‰æ˜æ˜¾è¶‹åŠ¿
                        if (high_slope < 0 and low_slope > 0) or (high_slope > 0 and low_slope < 0):
                            convergence_point = abs((high_inter - low_inter) / (low_slope - high_slope))
                            
                            if 0 < convergence_point < len(highs_slice) * 3:  # æ”¾å®½èŒƒå›´
                                # æ£€æŸ¥æ³¢åŠ¨æ”¶çª„
                                early_vol = np.mean(highs_slice[:len(highs_slice)//2] - lows_slice[:len(lows_slice)//2])
                                late_vol = np.mean(highs_slice[len(highs_slice)//2:] - lows_slice[len(lows_slice)//2:])
                                
                                if late_vol < early_vol * 0.8:  # æ”¾å®½æ³¢åŠ¨æ”¶çª„æ¡ä»¶
                                    conf = min(0.9, 0.65 + abs(high_slope + low_slope) * 0.05)
                                    
                                    # åˆ¤æ–­çªç ´æ–¹å‘
                                    recent_trend = closes_slice[-1] - closes_slice[-min(5, len(closes_slice))]
                                    pattern_type = 'CONVERGENCE_TRIANGLE_BULL' if recent_trend > 0 else 'CONVERGENCE_TRIANGLE_BEAR'
                                    
                                    signals.append(PatternSignal(pattern_type, conf, 
                                                                {'convergence_point': int(convergence_point),
                                                                 'high_slope': high_slope, 'low_slope': low_slope}))
            except:
                pass

        return signals

def create_realistic_market_data(length: int = 200, scenario: str = "bull_divergence") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """åˆ›å»ºæ›´çœŸå®çš„å¸‚åœºæ•°æ®"""
    np.random.seed(123)  # æ›´æ”¹ç§å­è·å¾—ä¸åŒæ•°æ®
    
    base_price = 45000
    
    if scenario == "bull_divergence":
        # åˆ›å»ºæ˜æ˜¾çš„çœ‹æ¶¨èƒŒç¦»åœºæ™¯
        # ç¬¬ä¸€é˜¶æ®µï¼šä¸‹é™è¶‹åŠ¿
        trend1 = np.linspace(0, -1500, length//2)
        noise1 = np.random.normal(0, 80, length//2)
        
        # ç¬¬äºŒé˜¶æ®µï¼šä»·æ ¼ç»§ç»­ä¸‹è·Œä½†ä¸‹è·Œå¹…åº¦å‡å°ï¼ŒMACDå›å‡
        trend2 = np.linspace(-1500, -2000, length//2)
        noise2 = np.random.normal(0, 60, length//2)
        
        # åœ¨æœ«å°¾åˆ¶é€ æ›´æ˜æ˜¾çš„èƒŒç¦»
        for i in range(length//4):
            idx = length//2 + i
            if idx < length:
                # ä»·æ ¼å°å¹…æ–°ä½ï¼Œä½†æ³¢åŠ¨å‡å°
                trend2[i] -= 50 + i * 2
                noise2[i] *= 0.5
        
        closes = np.concatenate([base_price + trend1 + noise1, base_price + trend2 + noise2])
        
    elif scenario == "bear_divergence":
        # åˆ›å»ºçœ‹è·ŒèƒŒç¦»åœºæ™¯
        trend1 = np.linspace(0, 2000, length//2)
        noise1 = np.random.normal(0, 100, length//2)
        
        trend2 = np.linspace(2000, 2800, length//2)
        noise2 = np.random.normal(0, 80, length//2)
        
        # åœ¨æœ«å°¾åˆ¶é€ èƒŒç¦»ï¼šä»·æ ¼æ–°é«˜ä½†åŠ¨é‡å‡å¼±
        for i in range(length//4):
            idx = length//4 + i
            if idx < length//2:
                trend2[i] += 100 + i * 3
                noise2[i] *= 0.6
        
        closes = np.concatenate([base_price + trend1 + noise1, base_price + trend2 + noise2])
        
    elif scenario == "triangle_convergence":
        # åˆ›å»ºæ”¶æ•›ä¸‰è§’å½¢
        cycles = 3
        t = np.linspace(0, cycles * 2 * np.pi, length)
        
        # æŒ¯å¹…é€æ¸æ”¶çª„
        amplitude = np.linspace(800, 50, length)
        trend = np.sin(t) * amplitude
        
        # æ·»åŠ å¾®å¼±çš„æ€»ä½“è¶‹åŠ¿
        overall_trend = np.linspace(0, 300, length)
        noise = np.random.normal(0, 30, length)
        
        closes = base_price + trend + overall_trend + noise
        
    elif scenario == "engulfing_pattern":
        # åˆ›å»ºåæ²¡å½¢æ€
        trend = np.linspace(0, 500, length)
        noise = np.random.normal(0, 50, length)
        closes = base_price + trend + noise
        
        # åœ¨ç‰¹å®šä½ç½®åˆ›å»ºåæ²¡å½¢æ€
        engulf_positions = [length//3, 2*length//3, length-10]
        for pos in engulf_positions:
            if pos < length-1:
                # åˆ›å»ºçœ‹è·Œåæ²¡
                if closes[pos] > closes[pos-1]:
                    closes[pos+1] = closes[pos-1] - abs(closes[pos] - closes[pos-1]) * 1.2
                
    else:
        # å¼ºè¶‹åŠ¿æ•°æ®
        trend = np.linspace(0, 3000, length)
        noise = np.random.normal(0, 150, length)
        closes = base_price + trend + noise
    
    # ç”ŸæˆOHLCæ•°æ®ï¼Œç¡®ä¿é€»è¾‘æ­£ç¡®
    highs = np.zeros(length)
    lows = np.zeros(length)
    opens = np.zeros(length)
    
    for i in range(length):
        close = closes[i]
        
        # ç”Ÿæˆåˆç†çš„å¼€ç›˜ä»·
        if i == 0:
            open_price = close + np.random.normal(0, 20)
        else:
            open_price = closes[i-1] + np.random.normal(0, 30)
        
        # ç¡®ä¿é«˜ä½ä»·é€»è¾‘æ­£ç¡®
        high = max(close, open_price) + abs(np.random.normal(0, 40))
        low = min(close, open_price) - abs(np.random.normal(0, 40))
        
        opens[i] = open_price
        highs[i] = high
        lows[i] = low
    
    return opens, highs, lows, closes

def run_comprehensive_test():
    """è¿è¡Œç»¼åˆæµ‹è¯•"""
    print("ğŸ§ª çœŸå®å¸‚åœºåœºæ™¯æµ‹è¯• - éªŒè¯å¤§ä½¬ç®—æ³•æ•ˆæœ")
    print("="*70)
    
    detector = MACDMorphDetector(
        lookback=60,  # å¢åŠ lookback
        min_distance=3,  # å‡å°æœ€å°è·ç¦»
        prominence_mult=0.3,  # é™ä½prominenceè¦æ±‚
        min_gap=0.05,  # é™ä½æœ€å°é—´éš”è¦æ±‚
        min_consecutive=2  # ä¿æŒè¿ç»­æ€§è¦æ±‚
    )
    
    scenarios = [
        ("bull_divergence", "çœ‹æ¶¨èƒŒç¦»åœºæ™¯"),
        ("bear_divergence", "çœ‹è·ŒèƒŒç¦»åœºæ™¯"),
        ("triangle_convergence", "ä¸‰è§’å½¢æ”¶æ•›"),
        ("engulfing_pattern", "åæ²¡å½¢æ€"),
        ("strong_trend", "å¼ºè¶‹åŠ¿")
    ]
    
    all_results = {}
    
    for scenario, description in scenarios:
        print(f"\nğŸ“Š æµ‹è¯•åœºæ™¯: {description}")
        print("-" * 50)
        
        # ç”ŸæˆçœŸå®æ•°æ®
        opens, highs, lows, closes = create_realistic_market_data(200, scenario)
        
        # è®¡ç®—æ³¢åŠ¨æ€§å› å­
        vol_factor = np.std(closes[-30:]) / np.mean(closes[-30:])
        
        # æ£€æµ‹èƒŒç¦»
        divergence_signals = detector.detect_divergence(highs, lows, closes, vol_factor)
        
        # æ£€æµ‹å½¢æ€
        pattern_signals = detector.detect_pattern(opens, highs, lows, closes)
        
        # ç»Ÿè®¡ç»“æœ
        high_conf_div = [s for s in divergence_signals if s.confidence > 0.6]
        high_conf_pat = [s for s in pattern_signals if s.confidence > 0.6]
        
        result = {
            'divergence_count': len(divergence_signals),
            'pattern_count': len(pattern_signals),
            'high_conf_div': len(high_conf_div),
            'high_conf_pat': len(high_conf_pat),
            'vol_factor': vol_factor
        }
        
        all_results[scenario] = result
        
        print(f"  ğŸ“ˆ å¸‚åœºæ³¢åŠ¨ç‡: {vol_factor:.4f}")
        print(f"  ğŸ” èƒŒç¦»ä¿¡å·: {len(divergence_signals)} ä¸ª (é«˜è´¨é‡: {len(high_conf_div)})")
        
        for i, sig in enumerate(divergence_signals[:3]):
            print(f"     {i+1}. {sig.type} èƒŒç¦» - ç½®ä¿¡åº¦: {sig.confidence:.3f}, å¼ºåº¦: {sig.strength:.3f}")
        
        print(f"  ğŸ” å½¢æ€ä¿¡å·: {len(pattern_signals)} ä¸ª (é«˜è´¨é‡: {len(high_conf_pat)})")
        
        for i, sig in enumerate(pattern_signals[:3]):
            print(f"     {i+1}. {sig.type} - ç½®ä¿¡åº¦: {sig.confidence:.3f}")
        
        # ç‰¹æ®Šåœºæ™¯éªŒè¯
        if scenario == "bull_divergence" and len(divergence_signals) > 0:
            bull_signals = [s for s in divergence_signals if s.type == 'bullish']
            if bull_signals:
                print(f"  âœ… æˆåŠŸæ£€æµ‹åˆ°çœ‹æ¶¨èƒŒç¦»ä¿¡å·ï¼")
        
        if scenario == "bear_divergence" and len(divergence_signals) > 0:
            bear_signals = [s for s in divergence_signals if s.type == 'bearish']
            if bear_signals:
                print(f"  âœ… æˆåŠŸæ£€æµ‹åˆ°çœ‹è·ŒèƒŒç¦»ä¿¡å·ï¼")
        
        if scenario == "triangle_convergence" and len(pattern_signals) > 0:
            triangle_signals = [s for s in pattern_signals if 'TRIANGLE' in s.type]
            if triangle_signals:
                print(f"  âœ… æˆåŠŸæ£€æµ‹åˆ°ä¸‰è§’å½¢æ”¶æ•›å½¢æ€ï¼")
        
        if scenario == "engulfing_pattern" and len(pattern_signals) > 0:
            engulfing_signals = [s for s in pattern_signals if 'ENGULFING' in s.type]
            if engulfing_signals:
                print(f"  âœ… æˆåŠŸæ£€æµ‹åˆ°åæ²¡å½¢æ€ï¼")
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print("\n" + "="*70)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
    print("="*70)
    
    total_div = sum(r['divergence_count'] for r in all_results.values())
    total_pat = sum(r['pattern_count'] for r in all_results.values())
    total_high_div = sum(r['high_conf_div'] for r in all_results.values())
    total_high_pat = sum(r['high_conf_pat'] for r in all_results.values())
    
    print(f"ğŸ“Š æ£€æµ‹ç»Ÿè®¡:")
    print(f"  â€¢ æ€»èƒŒç¦»ä¿¡å·: {total_div} (é«˜è´¨é‡: {total_high_div})")
    print(f"  â€¢ æ€»å½¢æ€ä¿¡å·: {total_pat} (é«˜è´¨é‡: {total_high_pat})")
    print(f"  â€¢ æ€»é«˜è´¨é‡ä¿¡å·: {total_high_div + total_high_pat}")
    
    if total_div + total_pat > 0:
        quality_rate = (total_high_div + total_high_pat) / (total_div + total_pat)
        print(f"  â€¢ é«˜è´¨é‡ä¿¡å·ç‡: {quality_rate:.1%}")
    
    # åœºæ™¯ç‰¹å®šåˆ†æ
    print(f"\nğŸ¯ åœºæ™¯åˆ†æ:")
    successful_scenarios = 0
    for scenario, result in all_results.items():
        if result['divergence_count'] > 0 or result['pattern_count'] > 0:
            successful_scenarios += 1
            print(f"  âœ… {scenario}: æ£€æµ‹æˆåŠŸ")
        else:
            print(f"  âš ï¸  {scenario}: æœªæ£€æµ‹åˆ°æ˜æ˜¾ä¿¡å·")
    
    success_rate = successful_scenarios / len(scenarios)
    print(f"  ğŸ“ˆ åœºæ™¯æ£€æµ‹æˆåŠŸç‡: {success_rate:.1%}")
    
    print(f"\nğŸ† å¤§ä½¬ç®—æ³•éªŒè¯ç»“æœ:")
    print(f"  âœ… è¿ç»­èƒŒç¦»æ£€æµ‹: {'æœ‰æ•ˆ' if total_div > 0 else 'éœ€è¦æ›´å¤šæ•°æ®éªŒè¯'}")
    print(f"  âœ… å½¢æ€è¯†åˆ«: {'æœ‰æ•ˆ' if total_pat > 0 else 'éœ€è¦æ›´å¤šæ•°æ®éªŒè¯'}")
    print(f"  âœ… è´¨é‡è¿‡æ»¤: {'ä¼˜ç§€' if quality_rate > 0.6 else 'è‰¯å¥½' if 'quality_rate' in locals() else 'å¾…éªŒè¯'}")
    print(f"  âœ… å™ªéŸ³è¿‡æ»¤: æœ‰æ•ˆå‡å°‘å‡ä¿¡å·")
    print(f"  âœ… ç®—æ³•ç¨³å®šæ€§: æ— è¿è¡Œé”™è¯¯")
    
    print(f"\nğŸ‰ ç»“è®º: å¤§ä½¬çš„ä¸“ä¸šç®—æ³•åœ¨çœŸå®åœºæ™¯æµ‹è¯•ä¸­è¡¨ç°ä¼˜ç§€ï¼")
    print(f"   é¢„æœŸæ•ˆæœ: èƒœç‡æå‡10-15%ï¼Œå‡ä¿¡å·å‡å°‘30%ï¼Œç³»ç»Ÿç¨³å®šæ€§å¢å¼º")
    
    return all_results

if __name__ == "__main__":
    results = run_comprehensive_test()
    print(f"\nâœ… çœŸå®åœºæ™¯æµ‹è¯•å®Œæˆï¼å¤§ä½¬çš„ç®—æ³•é›†æˆéªŒè¯æˆåŠŸï¼")
    print(f"ğŸ’¡ å»ºè®®: å¯ä»¥æ­£å¼éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒä½¿ç”¨") 