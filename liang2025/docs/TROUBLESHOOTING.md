# ğŸ”§ æ•…éšœæ’é™¤æŒ‡å—

## ğŸ“‹ ç›®å½•

- [å¿«é€Ÿè¯Šæ–­](#å¿«é€Ÿè¯Šæ–­)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [ç³»ç»Ÿé—®é¢˜](#ç³»ç»Ÿé—®é¢˜)
- [é…ç½®é—®é¢˜](#é…ç½®é—®é¢˜)
- [æ•°æ®é—®é¢˜](#æ•°æ®é—®é¢˜)
- [æ€§èƒ½é—®é¢˜](#æ€§èƒ½é—®é¢˜)
- [ç½‘ç»œé—®é¢˜](#ç½‘ç»œé—®é¢˜)
- [è°ƒè¯•å·¥å…·](#è°ƒè¯•å·¥å…·)
- [æ—¥å¿—åˆ†æ](#æ—¥å¿—åˆ†æ)
- [ç´§æ€¥å¤„ç†](#ç´§æ€¥å¤„ç†)

## ğŸš¨ å¿«é€Ÿè¯Šæ–­

### ç³»ç»Ÿå¥åº·æ£€æŸ¥

```bash
# å¿«é€Ÿç³»ç»Ÿæ£€æŸ¥è„šæœ¬
#!/bin/bash

echo "ğŸ” ç³»ç»Ÿå¥åº·æ£€æŸ¥..."

# æ£€æŸ¥Pythonç¯å¢ƒ
python --version
echo "âœ… Pythonç‰ˆæœ¬æ£€æŸ¥å®Œæˆ"

# æ£€æŸ¥ä¾èµ–å®‰è£…
python -c "import numpy, pandas, scipy, redis, pymongo" 2>/dev/null && echo "âœ… æ ¸å¿ƒä¾èµ–æ­£å¸¸" || echo "âŒ ä¾èµ–ç¼ºå¤±"

# æ£€æŸ¥é…ç½®æ–‡ä»¶
test -f config/config.json && echo "âœ… é…ç½®æ–‡ä»¶å­˜åœ¨" || echo "âŒ é…ç½®æ–‡ä»¶ç¼ºå¤±"

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
redis-cli ping 2>/dev/null && echo "âœ… Redisè¿æ¥æ­£å¸¸" || echo "âŒ Redisè¿æ¥å¤±è´¥"

# æ£€æŸ¥APIè¿æ¥
curl -s "https://api.binance.com/api/v3/ping" >/dev/null && echo "âœ… Binance APIæ­£å¸¸" || echo "âŒ Binance APIå¼‚å¸¸"

# æ£€æŸ¥ç³»ç»Ÿèµ„æº
echo "ğŸ’» ç³»ç»Ÿèµ„æºçŠ¶æ€:"
free -h
df -h
```

### æ•…éšœè¯Šæ–­æµç¨‹

```mermaid
graph TD
    A[ç³»ç»Ÿå¯åŠ¨å¤±è´¥] --> B{æ£€æŸ¥é”™è¯¯æ—¥å¿—}
    B --> C[é…ç½®æ–‡ä»¶é”™è¯¯]
    B --> D[ä¾èµ–ç¼ºå¤±]
    B --> E[ç½‘ç»œè¿æ¥é—®é¢˜]
    B --> F[èµ„æºä¸è¶³]
    
    C --> G[æ£€æŸ¥config.jsonè¯­æ³•]
    D --> H[é‡æ–°å®‰è£…ä¾èµ–]
    E --> I[æ£€æŸ¥ç½‘ç»œå’Œé˜²ç«å¢™]
    F --> J[é‡Šæ”¾ç³»ç»Ÿèµ„æº]
    
    G --> K[ä¿®å¤é…ç½®]
    H --> L[pip install -r requirements.txt]
    I --> M[é…ç½®ä»£ç†æˆ–VPN]
    J --> N[å…³é—­ä¸å¿…è¦ç¨‹åº]
```

## â“ å¸¸è§é—®é¢˜

### Q1: ç³»ç»Ÿå¯åŠ¨å¤±è´¥

**é”™è¯¯ä¿¡æ¯**: `ModuleNotFoundError: No module named 'xxx'`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# 2. é‡æ–°å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 3. æ£€æŸ¥Pythonè·¯å¾„
python -c "import sys; print(sys.path)"

# 4. æ‰‹åŠ¨å®‰è£…ç¼ºå¤±æ¨¡å—
pip install xxx
```

### Q2: APIè¿æ¥è¶…æ—¶

**é”™è¯¯ä¿¡æ¯**: `ConnectionError: HTTPSConnectionPool`

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. æ£€æŸ¥ç½‘ç»œè¿æ¥
import requests
try:
    response = requests.get("https://api.binance.com/api/v3/ping", timeout=5)
    print("ç½‘ç»œè¿æ¥æ­£å¸¸")
except requests.exceptions.Timeout:
    print("ç½‘ç»œè¿æ¥è¶…æ—¶")
except requests.exceptions.ConnectionError:
    print("æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨")

# 2. é…ç½®ä»£ç†
proxies = {
    'http': 'http://proxy.example.com:8080',
    'https': 'http://proxy.example.com:8080'
}

# 3. å¢åŠ è¶…æ—¶æ—¶é—´
config.jsonä¸­ä¿®æ”¹ï¼š
{
    "api": {
        "binance": {
            "timeout": 60
        }
    }
}
```

### Q3: å†…å­˜ä½¿ç”¨è¿‡é«˜

**é”™è¯¯ä¿¡æ¯**: `MemoryError` æˆ–ç³»ç»Ÿå¡é¡¿

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -h
top -p $(pgrep -f python)

# 2. é™åˆ¶æ•°æ®é‡
config.jsonä¸­ä¿®æ”¹ï¼š
{
    "trading": {
        "lookback_period": 50,  # å‡å°‘å›çœ‹å‘¨æœŸ
        "max_positions": 2      # å‡å°‘æœ€å¤§æŒä»“æ•°
    }
}

# 3. å¯ç”¨å†…å­˜é™åˆ¶
python -c "import resource; resource.setrlimit(resource.RLIMIT_AS, (2*1024*1024*1024, -1))"
```

### Q4: æ•°æ®åŒæ­¥é—®é¢˜

**é”™è¯¯ä¿¡æ¯**: `Data validation failed` æˆ–æ•°æ®ä¸ä¸€è‡´

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. æ¸…ç†ç¼“å­˜
redis-cli FLUSHALL

# 2. é‡ç½®æ•°æ®åº“
python scripts/reset_database.py

# 3. å¼ºåˆ¶é‡æ–°è·å–æ•°æ®
python scripts/refresh_data.py --symbol BTCUSDT --force

# 4. æ£€æŸ¥æ•°æ®è´¨é‡
python scripts/validate_data.py
```

## ğŸ–¥ï¸ ç³»ç»Ÿé—®é¢˜

### å¯åŠ¨é—®é¢˜

#### é—®é¢˜ï¼šPythonç‰ˆæœ¬ä¸å…¼å®¹
```bash
# é”™è¯¯ä¿¡æ¯
SyntaxError: invalid syntax (f-string)

# è§£å†³æ–¹æ¡ˆ
# 1. æ£€æŸ¥Pythonç‰ˆæœ¬
python --version  # éœ€è¦3.8+

# 2. å‡çº§Python
# Ubuntu/Debian
sudo apt update
sudo apt install python3.10

# macOS
brew install python@3.10

# 3. åˆ›å»ºæ–°è™šæ‹Ÿç¯å¢ƒ
python3.10 -m venv venv
source venv/bin/activate
```

#### é—®é¢˜ï¼šæƒé™é”™è¯¯
```bash
# é”™è¯¯ä¿¡æ¯
PermissionError: [Errno 13] Permission denied: 'logs/trading_system.log'

# è§£å†³æ–¹æ¡ˆ
# 1. åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p logs
chmod 755 logs

# 2. ä¿®æ”¹æ–‡ä»¶æƒé™
sudo chown -R $USER:$USER logs/
chmod 644 logs/*.log

# 3. ä½¿ç”¨ç›¸å¯¹è·¯å¾„
config.jsonä¸­ä¿®æ”¹ï¼š
{
    "logging": {
        "file": "./logs/trading_system.log"
    }
}
```

### æ€§èƒ½é—®é¢˜

#### é—®é¢˜ï¼šCPUä½¿ç”¨ç‡è¿‡é«˜
```bash
# è¯Šæ–­æ­¥éª¤
# 1. æŸ¥çœ‹è¿›ç¨‹çŠ¶æ€
htop
ps aux | grep python

# 2. Pythonæ€§èƒ½åˆ†æ
python -m cProfile -o profile.stats main.py

# 3. åˆ†ææ€§èƒ½ç“¶é¢ˆ
python -c "
import pstats
p = pstats.Stats('profile.stats')
p.sort_stats('cumulative').print_stats(20)
"

# ä¼˜åŒ–æ–¹æ¡ˆ
# 1. å‡å°‘è®¡ç®—é¢‘ç‡
config.jsonä¸­ä¿®æ”¹ï¼š
{
    "system": {
        "resource_monitoring": {
            "check_interval": 60  # å¢åŠ æ£€æŸ¥é—´éš”
        }
    }
}

# 2. å¯ç”¨ç¼“å­˜
{
    "api": {
        "cache_enabled": true,
        "cache_ttl": 300
    }
}
```

#### é—®é¢˜ï¼šå†…å­˜æ³„æ¼
```python
# å†…å­˜ç›‘æ§è„šæœ¬
import psutil
import gc
import tracemalloc

def monitor_memory():
    # å¯ç”¨å†…å­˜è¿½è¸ª
    tracemalloc.start()
    
    process = psutil.Process()
    
    while True:
        # è·å–å†…å­˜ä½¿ç”¨
        memory_info = process.memory_info()
        memory_percent = process.memory_percent()
        
        print(f"å†…å­˜ä½¿ç”¨: {memory_info.rss / 1024 / 1024:.2f} MB ({memory_percent:.1f}%)")
        
        # è·å–å†…å­˜å¿«ç…§
        snapshot = tracemalloc.take_snapshot()
        top_stats = snapshot.statistics('lineno')
        
        print("Top 10 å†…å­˜ä½¿ç”¨:")
        for stat in top_stats[:10]:
            print(stat)
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        
        time.sleep(60)

# å†…å­˜ä¼˜åŒ–å»ºè®®
# 1. å®šæœŸæ¸…ç†ç¼“å­˜
def cleanup_cache():
    import gc
    gc.collect()
    
    # æ¸…ç†Redisç¼“å­˜
    redis_client.flushdb()
    
    # æ¸…ç†å†…å­˜ç¼“å­˜
    cache_manager.clear_all()

# 2. é™åˆ¶æ•°æ®é‡
def limit_data_size():
    # é™åˆ¶Kçº¿æ•°æ®é‡
    MAX_KLINES = 1000
    
    # é™åˆ¶ä¿¡å·å†å²
    MAX_SIGNALS = 500
    
    # å®šæœŸæ¸…ç†å†å²æ•°æ®
    cleanup_old_data()
```

## âš™ï¸ é…ç½®é—®é¢˜

### é…ç½®æ–‡ä»¶é”™è¯¯

#### é—®é¢˜ï¼šJSONè¯­æ³•é”™è¯¯
```bash
# é”™è¯¯ä¿¡æ¯
JSONDecodeError: Expecting ',' delimiter: line 15 column 5

# è§£å†³æ–¹æ¡ˆ
# 1. éªŒè¯JSONæ ¼å¼
python -c "
import json
with open('config/config.json', 'r') as f:
    json.load(f)
print('JSONæ ¼å¼æ­£ç¡®')
"

# 2. ä½¿ç”¨JSONæ ¼å¼åŒ–å·¥å…·
pip install jsonschema
python scripts/validate_config.py

# 3. åœ¨çº¿JSONéªŒè¯
# https://jsonlint.com/
```

#### é—®é¢˜ï¼šé…ç½®å‚æ•°æ— æ•ˆ
```python
# é…ç½®éªŒè¯è„šæœ¬
def validate_config():
    import json
    from jsonschema import validate
    
    # é…ç½®schema
    schema = {
        "type": "object",
        "properties": {
            "trading": {
                "type": "object",
                "properties": {
                    "risk_per_trade": {
                        "type": "number",
                        "minimum": 0.001,
                        "maximum": 0.1
                    },
                    "max_leverage": {
                        "type": "number",
                        "minimum": 1,
                        "maximum": 100
                    }
                },
                "required": ["risk_per_trade", "max_leverage"]
            }
        },
        "required": ["trading"]
    }
    
    # éªŒè¯é…ç½®
    with open('config/config.json', 'r') as f:
        config = json.load(f)
    
    try:
        validate(config, schema)
        print("é…ç½®éªŒè¯é€šè¿‡")
    except Exception as e:
        print(f"é…ç½®éªŒè¯å¤±è´¥: {e}")
```

### ç¯å¢ƒå˜é‡é—®é¢˜

#### é—®é¢˜ï¼šç¯å¢ƒå˜é‡æœªè®¾ç½®
```bash
# é”™è¯¯ä¿¡æ¯
KeyError: 'BINANCE_API_KEY'

# è§£å†³æ–¹æ¡ˆ
# 1. æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $BINANCE_API_KEY

# 2. åˆ›å»º.envæ–‡ä»¶
cat > .env << EOF
BINANCE_API_KEY=your_api_key
BINANCE_API_SECRET=your_api_secret
TELEGRAM_BOT_TOKEN=your_bot_token
EOF

# 3. åŠ è½½ç¯å¢ƒå˜é‡
source .env
python -c "import os; print(os.getenv('BINANCE_API_KEY'))"

# 4. ä½¿ç”¨python-dotenv
pip install python-dotenv
python -c "
from dotenv import load_dotenv
load_dotenv()
import os
print(os.getenv('BINANCE_API_KEY'))
"
```

## ğŸ“Š æ•°æ®é—®é¢˜

### æ•°æ®è·å–å¤±è´¥

#### é—®é¢˜ï¼šAPIé™æµ
```python
# é”™è¯¯ä¿¡æ¯
HTTPError: 429 Too Many Requests

# è§£å†³æ–¹æ¡ˆ
import time
import asyncio
from functools import wraps

def rate_limit(calls_per_second=1):
    def decorator(func):
        last_called = [0.0]
        
        @wraps(func)
        async def wrapper(*args, **kwargs):
            elapsed = time.time() - last_called[0]
            left_to_wait = 1.0 / calls_per_second - elapsed
            
            if left_to_wait > 0:
                await asyncio.sleep(left_to_wait)
            
            ret = await func(*args, **kwargs)
            last_called[0] = time.time()
            return ret
        
        return wrapper
    return decorator

# ä½¿ç”¨é™æµè£…é¥°å™¨
@rate_limit(calls_per_second=0.5)  # æ¯2ç§’ä¸€æ¬¡è°ƒç”¨
async def fetch_data(symbol):
    # APIè°ƒç”¨ä»£ç 
    pass
```

#### é—®é¢˜ï¼šæ•°æ®è´¨é‡é—®é¢˜
```python
# æ•°æ®éªŒè¯è„šæœ¬
def validate_kline_data(data):
    """éªŒè¯Kçº¿æ•°æ®è´¨é‡"""
    issues = []
    
    # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
    required_fields = ['open', 'high', 'low', 'close', 'volume']
    for field in required_fields:
        if field not in data:
            issues.append(f"ç¼ºå°‘å­—æ®µ: {field}")
    
    # æ£€æŸ¥ä»·æ ¼é€»è¾‘
    if data['high'] < data['low']:
        issues.append("æœ€é«˜ä»·å°äºæœ€ä½ä»·")
    
    if data['high'] < data['open'] or data['high'] < data['close']:
        issues.append("æœ€é«˜ä»·å¼‚å¸¸")
    
    if data['low'] > data['open'] or data['low'] > data['close']:
        issues.append("æœ€ä½ä»·å¼‚å¸¸")
    
    # æ£€æŸ¥æˆäº¤é‡
    if data['volume'] < 0:
        issues.append("æˆäº¤é‡ä¸ºè´Ÿæ•°")
    
    return issues

# æ•°æ®æ¸…æ´—
def clean_data(data):
    """æ¸…æ´—å¼‚å¸¸æ•°æ®"""
    cleaned_data = []
    
    for item in data:
        issues = validate_kline_data(item)
        if not issues:
            cleaned_data.append(item)
        else:
            print(f"æ•°æ®å¼‚å¸¸: {issues}")
    
    return cleaned_data
```

### æ•°æ®åº“é—®é¢˜

#### é—®é¢˜ï¼šRedisè¿æ¥å¤±è´¥
```bash
# é”™è¯¯ä¿¡æ¯
ConnectionError: Error connecting to Redis

# è§£å†³æ–¹æ¡ˆ
# 1. æ£€æŸ¥RedisæœåŠ¡çŠ¶æ€
redis-cli ping
systemctl status redis

# 2. å¯åŠ¨RedisæœåŠ¡
sudo systemctl start redis
sudo systemctl enable redis

# 3. æ£€æŸ¥Redisé…ç½®
redis-cli CONFIG GET "*"

# 4. é‡ç½®Redis
redis-cli FLUSHALL
sudo systemctl restart redis
```

#### é—®é¢˜ï¼šMongoDBè¿æ¥å¤±è´¥
```bash
# é”™è¯¯ä¿¡æ¯
ServerSelectionTimeoutError: No servers available

# è§£å†³æ–¹æ¡ˆ
# 1. æ£€æŸ¥MongoDBçŠ¶æ€
mongo --eval "db.runCommand('ping')"
systemctl status mongod

# 2. å¯åŠ¨MongoDB
sudo systemctl start mongod
sudo systemctl enable mongod

# 3. æ£€æŸ¥è¿æ¥å­—ç¬¦ä¸²
python -c "
import pymongo
client = pymongo.MongoClient('mongodb://localhost:27017/')
print(client.server_info())
"
```

## ğŸŒ ç½‘ç»œé—®é¢˜

### è¿æ¥è¶…æ—¶

#### é—®é¢˜ï¼šAPIè¿æ¥è¶…æ—¶
```python
# ç½‘ç»œè¯Šæ–­è„šæœ¬
import requests
import time

def diagnose_network():
    """ç½‘ç»œè¯Šæ–­"""
    endpoints = [
        "https://api.binance.com/api/v3/ping",
        "https://api.coingecko.com/api/v3/ping",
        "https://api.telegram.org/bot<token>/getMe"
    ]
    
    for endpoint in endpoints:
        try:
            start_time = time.time()
            response = requests.get(endpoint, timeout=10)
            latency = (time.time() - start_time) * 1000
            
            print(f"âœ… {endpoint}: {response.status_code} ({latency:.2f}ms)")
        except requests.exceptions.Timeout:
            print(f"âŒ {endpoint}: è¶…æ—¶")
        except requests.exceptions.ConnectionError:
            print(f"âŒ {endpoint}: è¿æ¥å¤±è´¥")
        except Exception as e:
            print(f"âŒ {endpoint}: {e}")

# ç½‘ç»œä¼˜åŒ–
def optimize_network():
    """ç½‘ç»œä¼˜åŒ–è®¾ç½®"""
    import aiohttp
    
    # è¿æ¥æ± é…ç½®
    connector = aiohttp.TCPConnector(
        limit=100,           # æ€»è¿æ¥æ•°é™åˆ¶
        limit_per_host=20,   # æ¯ä¸ªä¸»æœºè¿æ¥æ•°é™åˆ¶
        ttl_dns_cache=300,   # DNSç¼“å­˜æ—¶é—´
        use_dns_cache=True,  # å¯ç”¨DNSç¼“å­˜
        keepalive_timeout=30 # ä¿æŒè¿æ¥æ—¶é—´
    )
    
    # è¶…æ—¶é…ç½®
    timeout = aiohttp.ClientTimeout(
        total=30,      # æ€»è¶…æ—¶æ—¶é—´
        connect=10,    # è¿æ¥è¶…æ—¶
        sock_read=10   # è¯»å–è¶…æ—¶
    )
    
    return aiohttp.ClientSession(
        connector=connector,
        timeout=timeout
    )
```

### ä»£ç†é…ç½®

#### é—®é¢˜ï¼šéœ€è¦ä»£ç†è®¿é—®
```python
# ä»£ç†é…ç½®
def setup_proxy():
    """è®¾ç½®ä»£ç†"""
    import os
    
    # ç¯å¢ƒå˜é‡è®¾ç½®
    os.environ['HTTP_PROXY'] = 'http://proxy.example.com:8080'
    os.environ['HTTPS_PROXY'] = 'http://proxy.example.com:8080'
    
    # requestsä»£ç†
    proxies = {
        'http': 'http://proxy.example.com:8080',
        'https': 'http://proxy.example.com:8080'
    }
    
    # aiohttpä»£ç†
    import aiohttp
    
    async def fetch_with_proxy(url):
        async with aiohttp.ClientSession() as session:
            async with session.get(url, proxy='http://proxy.example.com:8080') as response:
                return await response.json()
```

## ğŸ”§ è°ƒè¯•å·¥å…·

### æ—¥å¿—è°ƒè¯•

#### å¯ç”¨è¯¦ç»†æ—¥å¿—
```python
# æ—¥å¿—é…ç½®
import logging

# è®¾ç½®æ—¥å¿—çº§åˆ«
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('debug.log'),
        logging.StreamHandler()
    ]
)

# ç‰¹å®šæ¨¡å—æ—¥å¿—
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# ç¬¬ä¸‰æ–¹åº“æ—¥å¿—
logging.getLogger('requests').setLevel(logging.DEBUG)
logging.getLogger('aiohttp').setLevel(logging.DEBUG)
```

#### æ—¥å¿—åˆ†æå·¥å…·
```bash
# æ—¥å¿—åˆ†æè„šæœ¬
#!/bin/bash

echo "ğŸ“Š æ—¥å¿—åˆ†ææŠ¥å‘Š"
echo "=================="

# é”™è¯¯ç»Ÿè®¡
echo "ğŸ”´ é”™è¯¯ç»Ÿè®¡:"
grep -c "ERROR" logs/trading_system.log

# è­¦å‘Šç»Ÿè®¡
echo "ğŸŸ¡ è­¦å‘Šç»Ÿè®¡:"
grep -c "WARNING" logs/trading_system.log

# æœ€è¿‘é”™è¯¯
echo "ğŸ” æœ€è¿‘é”™è¯¯:"
grep "ERROR" logs/trading_system.log | tail -10

# æ€§èƒ½ç»Ÿè®¡
echo "ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:"
grep "execution_time" logs/trading_system.log | awk '{sum+=$NF; count++} END {print "å¹³å‡æ‰§è¡Œæ—¶é—´:", sum/count, "ms"}'

# å†…å­˜ä½¿ç”¨
echo "ğŸ’¾ å†…å­˜ä½¿ç”¨:"
grep "memory_usage" logs/trading_system.log | tail -5
```

### æ€§èƒ½åˆ†æ

#### æ€§èƒ½ç›‘æ§è„šæœ¬
```python
# æ€§èƒ½ç›‘æ§
import psutil
import time
import threading

class PerformanceMonitor:
    def __init__(self):
        self.monitoring = False
        self.stats = []
    
    def start_monitoring(self):
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        self.monitoring = False
        if hasattr(self, 'monitor_thread'):
            self.monitor_thread.join()
    
    def _monitor_loop(self):
        while self.monitoring:
            # è·å–ç³»ç»ŸçŠ¶æ€
            cpu_percent = psutil.cpu_percent()
            memory_percent = psutil.virtual_memory().percent
            
            # è·å–è¿›ç¨‹çŠ¶æ€
            process = psutil.Process()
            process_cpu = process.cpu_percent()
            process_memory = process.memory_percent()
            
            stats = {
                'timestamp': time.time(),
                'system_cpu': cpu_percent,
                'system_memory': memory_percent,
                'process_cpu': process_cpu,
                'process_memory': process_memory
            }
            
            self.stats.append(stats)
            
            # é™åˆ¶ç»Ÿè®¡æ•°æ®é‡
            if len(self.stats) > 1000:
                self.stats = self.stats[-500:]
            
            time.sleep(1)
    
    def get_report(self):
        if not self.stats:
            return "æ— æ€§èƒ½æ•°æ®"
        
        recent_stats = self.stats[-60:]  # æœ€è¿‘60ç§’
        
        avg_system_cpu = sum(s['system_cpu'] for s in recent_stats) / len(recent_stats)
        avg_system_memory = sum(s['system_memory'] for s in recent_stats) / len(recent_stats)
        avg_process_cpu = sum(s['process_cpu'] for s in recent_stats) / len(recent_stats)
        avg_process_memory = sum(s['process_memory'] for s in recent_stats) / len(recent_stats)
        
        return f"""
        ğŸ“Š æ€§èƒ½æŠ¥å‘Š (æœ€è¿‘60ç§’)
        ===================
        ç³»ç»ŸCPU: {avg_system_cpu:.1f}%
        ç³»ç»Ÿå†…å­˜: {avg_system_memory:.1f}%
        è¿›ç¨‹CPU: {avg_process_cpu:.1f}%
        è¿›ç¨‹å†…å­˜: {avg_process_memory:.1f}%
        """

# ä½¿ç”¨ç¤ºä¾‹
monitor = PerformanceMonitor()
monitor.start_monitoring()

# è¿è¡Œä¸€æ®µæ—¶é—´å
time.sleep(60)
print(monitor.get_report())

monitor.stop_monitoring()
```

## ğŸ“Š æ—¥å¿—åˆ†æ

### ç»“æ„åŒ–æ—¥å¿—æŸ¥è¯¢

```python
# æ—¥å¿—æŸ¥è¯¢å·¥å…·
import json
import re
from datetime import datetime

class LogAnalyzer:
    def __init__(self, log_file):
        self.log_file = log_file
    
    def search_errors(self, start_time=None, end_time=None):
        """æœç´¢é”™è¯¯æ—¥å¿—"""
        errors = []
        
        with open(self.log_file, 'r') as f:
            for line in f:
                if 'ERROR' in line:
                    # è§£ææ—¶é—´æˆ³
                    timestamp_match = re.search(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})', line)
                    if timestamp_match:
                        timestamp = datetime.strptime(timestamp_match.group(1), '%Y-%m-%d %H:%M:%S')
                        
                        # æ—¶é—´è¿‡æ»¤
                        if start_time and timestamp < start_time:
                            continue
                        if end_time and timestamp > end_time:
                            continue
                        
                        errors.append({
                            'timestamp': timestamp,
                            'message': line.strip()
                        })
        
        return errors
    
    def get_error_summary(self):
        """è·å–é”™è¯¯æ‘˜è¦"""
        errors = self.search_errors()
        
        # é”™è¯¯åˆ†ç±»
        error_types = {}
        for error in errors:
            # æå–é”™è¯¯ç±»å‹
            error_type = 'Unknown'
            if 'ConnectionError' in error['message']:
                error_type = 'ConnectionError'
            elif 'TimeoutError' in error['message']:
                error_type = 'TimeoutError'
            elif 'ValueError' in error['message']:
                error_type = 'ValueError'
            elif 'KeyError' in error['message']:
                error_type = 'KeyError'
            
            error_types[error_type] = error_types.get(error_type, 0) + 1
        
        return {
            'total_errors': len(errors),
            'error_types': error_types,
            'recent_errors': errors[-5:] if errors else []
        }

# ä½¿ç”¨ç¤ºä¾‹
analyzer = LogAnalyzer('logs/trading_system.log')
summary = analyzer.get_error_summary()
print(json.dumps(summary, indent=2, default=str))
```

### å®æ—¶æ—¥å¿—ç›‘æ§

```python
# å®æ—¶æ—¥å¿—ç›‘æ§
import asyncio
import aiofiles

class RealTimeLogMonitor:
    def __init__(self, log_file):
        self.log_file = log_file
        self.monitoring = False
        self.callbacks = []
    
    def add_callback(self, callback):
        """æ·»åŠ æ—¥å¿—å›è°ƒå‡½æ•°"""
        self.callbacks.append(callback)
    
    async def start_monitoring(self):
        """å¼€å§‹ç›‘æ§æ—¥å¿—"""
        self.monitoring = True
        
        async with aiofiles.open(self.log_file, 'r') as f:
            # ç§»åŠ¨åˆ°æ–‡ä»¶æœ«å°¾
            await f.seek(0, 2)
            
            while self.monitoring:
                # è¯»å–æ–°è¡Œ
                line = await f.readline()
                
                if line:
                    # è°ƒç”¨å›è°ƒå‡½æ•°
                    for callback in self.callbacks:
                        await callback(line.strip())
                else:
                    # æ²¡æœ‰æ–°è¡Œï¼Œç­‰å¾…
                    await asyncio.sleep(0.1)
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False

# å‘Šè­¦å›è°ƒ
async def error_alert(log_line):
    """é”™è¯¯å‘Šè­¦"""
    if 'ERROR' in log_line:
        print(f"ğŸš¨ é”™è¯¯å‘Šè­¦: {log_line}")
        # å‘é€é€šçŸ¥
        # await send_telegram_alert(log_line)

# ä½¿ç”¨ç¤ºä¾‹
monitor = RealTimeLogMonitor('logs/trading_system.log')
monitor.add_callback(error_alert)

# åœ¨åå°è¿è¡Œ
asyncio.create_task(monitor.start_monitoring())
```

## ğŸš¨ ç´§æ€¥å¤„ç†

### ç´§æ€¥åœæ­¢

```python
# ç´§æ€¥åœæ­¢è„šæœ¬
import signal
import sys
import asyncio

class EmergencyHandler:
    def __init__(self, trading_engine):
        self.trading_engine = trading_engine
        self.setup_signal_handlers()
    
    def setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
        signal.signal(signal.SIGINT, self.emergency_stop)
        signal.signal(signal.SIGTERM, self.emergency_stop)
    
    def emergency_stop(self, signum, frame):
        """ç´§æ€¥åœæ­¢å¤„ç†"""
        print("\nğŸš¨ æ”¶åˆ°ç´§æ€¥åœæ­¢ä¿¡å·")
        
        # å¼‚æ­¥åœæ­¢
        asyncio.create_task(self.graceful_shutdown())
    
    async def graceful_shutdown(self):
        """ä¼˜é›…åœæ­¢"""
        try:
            print("1. åœæ­¢æ–°è®¢å•...")
            await self.trading_engine.stop_new_orders()
            
            print("2. å–æ¶ˆå¾…å¤„ç†è®¢å•...")
            await self.trading_engine.cancel_pending_orders()
            
            print("3. ä¿å­˜çŠ¶æ€...")
            await self.trading_engine.save_state()
            
            print("4. å…³é—­è¿æ¥...")
            await self.trading_engine.close_connections()
            
            print("âœ… ç³»ç»Ÿå·²å®‰å…¨åœæ­¢")
            
        except Exception as e:
            print(f"âŒ åœæ­¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            sys.exit(0)

# ä½¿ç”¨ç¤ºä¾‹
handler = EmergencyHandler(trading_engine)
```

### æ•°æ®å¤‡ä»½

```python
# ç´§æ€¥æ•°æ®å¤‡ä»½
import json
import asyncio
from datetime import datetime

class EmergencyBackup:
    def __init__(self, config_manager):
        self.config = config_manager
        self.backup_dir = "emergency_backup"
    
    async def create_emergency_backup(self):
        """åˆ›å»ºç´§æ€¥å¤‡ä»½"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = f"{self.backup_dir}/emergency_{timestamp}"
        
        os.makedirs(backup_path, exist_ok=True)
        
        # å¤‡ä»½é…ç½®
        await self.backup_config(backup_path)
        
        # å¤‡ä»½æ•°æ®
        await self.backup_data(backup_path)
        
        # å¤‡ä»½æ—¥å¿—
        await self.backup_logs(backup_path)
        
        print(f"âœ… ç´§æ€¥å¤‡ä»½å®Œæˆ: {backup_path}")
        return backup_path
    
    async def backup_config(self, backup_path):
        """å¤‡ä»½é…ç½®æ–‡ä»¶"""
        config_files = [
            "config/config.json",
            ".env",
            "requirements.txt"
        ]
        
        for config_file in config_files:
            if os.path.exists(config_file):
                shutil.copy2(config_file, backup_path)
    
    async def backup_data(self, backup_path):
        """å¤‡ä»½æ•°æ®"""
        # å¤‡ä»½Redisæ•°æ®
        os.system(f"redis-cli BGSAVE")
        
        # å¤‡ä»½MongoDBæ•°æ®
        os.system(f"mongodump --out {backup_path}/mongodb_backup")
        
        # å¤‡ä»½äº¤æ˜“è®°å½•
        trading_records = await self.get_trading_records()
        with open(f"{backup_path}/trading_records.json", 'w') as f:
            json.dump(trading_records, f, indent=2, default=str)
    
    async def backup_logs(self, backup_path):
        """å¤‡ä»½æ—¥å¿—æ–‡ä»¶"""
        log_files = [
            "logs/trading_system.log",
            "logs/error.log",
            "logs/trading.log"
        ]
        
        for log_file in log_files:
            if os.path.exists(log_file):
                shutil.copy2(log_file, backup_path)

# ä½¿ç”¨ç¤ºä¾‹
backup = EmergencyBackup(config_manager)
await backup.create_emergency_backup()
```

### æ•…éšœæ¢å¤

```python
# æ•…éšœæ¢å¤è„šæœ¬
class DisasterRecovery:
    def __init__(self, backup_path):
        self.backup_path = backup_path
    
    async def recover_from_backup(self):
        """ä»å¤‡ä»½æ¢å¤"""
        try:
            print("ğŸ”„ å¼€å§‹æ•…éšœæ¢å¤...")
            
            # æ¢å¤é…ç½®
            await self.restore_config()
            
            # æ¢å¤æ•°æ®
            await self.restore_data()
            
            # éªŒè¯æ¢å¤
            await self.verify_recovery()
            
            print("âœ… æ•…éšœæ¢å¤å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ•…éšœæ¢å¤å¤±è´¥: {e}")
            raise
    
    async def restore_config(self):
        """æ¢å¤é…ç½®"""
        config_files = [
            "config.json",
            ".env"
        ]
        
        for config_file in config_files:
            backup_file = f"{self.backup_path}/{config_file}"
            if os.path.exists(backup_file):
                shutil.copy2(backup_file, config_file)
                print(f"âœ… æ¢å¤é…ç½®: {config_file}")
    
    async def restore_data(self):
        """æ¢å¤æ•°æ®"""
        # æ¢å¤Redisæ•°æ®
        redis_backup = f"{self.backup_path}/dump.rdb"
        if os.path.exists(redis_backup):
            os.system(f"redis-cli FLUSHALL")
            os.system(f"cp {redis_backup} /var/lib/redis/dump.rdb")
            os.system("sudo systemctl restart redis")
        
        # æ¢å¤MongoDBæ•°æ®
        mongodb_backup = f"{self.backup_path}/mongodb_backup"
        if os.path.exists(mongodb_backup):
            os.system(f"mongorestore --drop {mongodb_backup}")
    
    async def verify_recovery(self):
        """éªŒè¯æ¢å¤"""
        # éªŒè¯é…ç½®
        with open('config/config.json', 'r') as f:
            config = json.load(f)
        
        # éªŒè¯æ•°æ®åº“è¿æ¥
        redis_client = redis.Redis()
        redis_client.ping()
        
        # éªŒè¯MongoDBè¿æ¥
        mongo_client = pymongo.MongoClient()
        mongo_client.server_info()
        
        print("âœ… æ¢å¤éªŒè¯é€šè¿‡")

# ä½¿ç”¨ç¤ºä¾‹
recovery = DisasterRecovery("emergency_backup/emergency_20241201_143000")
await recovery.recover_from_backup()
```

## ğŸ“ è·å–å¸®åŠ©

### æŠ€æœ¯æ”¯æŒæ¸ é“

1. **åœ¨çº¿æ–‡æ¡£**: https://docs.trading-system.com
2. **GitHub Issues**: https://github.com/your-repo/trading-system/issues
3. **æŠ€æœ¯è®ºå›**: https://forum.trading-system.com
4. **é‚®ä»¶æ”¯æŒ**: support@trading-system.com

### é—®é¢˜æŠ¥å‘Šæ¨¡æ¿

```markdown
## é—®é¢˜æè¿°
ç®€è¦æè¿°é‡åˆ°çš„é—®é¢˜

## ç¯å¢ƒä¿¡æ¯
- æ“ä½œç³»ç»Ÿ: 
- Pythonç‰ˆæœ¬: 
- ç³»ç»Ÿç‰ˆæœ¬: 

## é‡ç°æ­¥éª¤
1. 
2. 
3. 

## é”™è¯¯ä¿¡æ¯
```
é”™è¯¯æ—¥å¿—ç²˜è´´åˆ°è¿™é‡Œ
```

## é¢„æœŸè¡Œä¸º
æè¿°é¢„æœŸçš„æ­£å¸¸è¡Œä¸º

## å®é™…è¡Œä¸º
æè¿°å®é™…å‘ç”Ÿçš„è¡Œä¸º

## é™„åŠ ä¿¡æ¯
- é…ç½®æ–‡ä»¶
- æ—¥å¿—æ–‡ä»¶
- æˆªå›¾
```

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [ç”¨æˆ·ä½¿ç”¨æŒ‡å—](USER_GUIDE.md)
- [APIå‚è€ƒæ–‡æ¡£](API_REFERENCE.md)
- [é…ç½®å‚æ•°è¯´æ˜](CONFIGURATION.md)
- [æ¶æ„è®¾è®¡æ–‡æ¡£](ARCHITECTURE.md)

---

ğŸ”§ **ç»´æŠ¤å»ºè®®**: å®šæœŸè¿›è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥ï¼ŒåŠæ—¶å¤„ç†è­¦å‘Šä¿¡æ¯ï¼Œå»ºç«‹å®Œå–„çš„ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶ã€‚ 